{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stable Roommates Matching for Pair Research\n",
    "This notebook analyzes the [Stable Roomates Matching](http://www.dcs.gla.ac.uk/~pat/jchoco/roommates/papers/Comp_sdarticle.pdf) algorithm with previous [Pair Research](http://pairresearch.io/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Libraries and Stable Roommates Matching Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis\n",
    "import multiprocessing as mp\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy\n",
    "from pymongo import MongoClient\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stable roommates and pair research modules\n",
    "from stable_roommates import verify_stability\n",
    "from stable_roommates import create_preference_matrix\n",
    "from stable_roommates import compute_matching_cardinality\n",
    "\n",
    "from pair_research import create_matching_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Analysis of Stable Roommates Matching on Pair Research Data\n",
    "Below, we analyze the impact of using the Stable Roommates algorithm on previous pairings. \n",
    "\n",
    "We begin by seeing\n",
    "1. How frequently can we find stable matchings? \n",
    "2. When stable matchings are not possible, for what reason do they fail?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Pairing Data from [pairresearch.io](http://pairresearch.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pairings',\n",
       " 'affinities_history',\n",
       " 'objectlabs-system',\n",
       " 'affinities',\n",
       " 'tasks_history',\n",
       " 'groups',\n",
       " 'pairs_history',\n",
       " 'users',\n",
       " 'tasks',\n",
       " 'objectlabs-system.admin.collections',\n",
       " 'meteor_accounts_loginServiceConfiguration']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbName = \"pair-research\"\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[dbName]\n",
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Users: 1910\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>services</th>\n",
       "      <th>emails</th>\n",
       "      <th>profile</th>\n",
       "      <th>groups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3EuAwtcy65oC2v4ox</td>\n",
       "      <td>2018-05-02 15:34:32.218</td>\n",
       "      <td>{'password': {}}</td>\n",
       "      <td>[{'address': 'GaryBland2014@U.NORTHWESTERN.EDU...</td>\n",
       "      <td>{'fullName': 'GaryBland2014@U.NORTHWESTERN.EDU'}</td>\n",
       "      <td>[{'groupId': 'TjwobnBm8xX9BTipw', 'role': {'_i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3Y7RFcwRG4fyDGJBM</td>\n",
       "      <td>2018-05-02 15:35:12.612</td>\n",
       "      <td>{'password': {}}</td>\n",
       "      <td>[{'address': 'EricaMinor2015@U.NORTHWESTERN.ED...</td>\n",
       "      <td>{'fullName': 'EricaMinor2015@U.NORTHWESTERN.EDU'}</td>\n",
       "      <td>[{'groupId': 'TjwobnBm8xX9BTipw', 'role': {'_i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2Lefr8WhP7DMFSbgY</td>\n",
       "      <td>2017-09-27 17:06:02.503</td>\n",
       "      <td>{'password': {'bcrypt': '$2a$10$djvQf78jjBEAGs...</td>\n",
       "      <td>[{'address': 'allisonlu2018@u.northwestern.edu...</td>\n",
       "      <td>{'fullName': 'Allison Lu', 'avatar': 'http://o...</td>\n",
       "      <td>[{'groupId': 'sM3z5FkZfsABqcj3g', 'role': {'ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2HxiToJbYpPzjp22y</td>\n",
       "      <td>2016-12-09 01:55:40.646</td>\n",
       "      <td>{'password': {'bcrypt': '$2a$10$n5KHTA./KfKgM....</td>\n",
       "      <td>[{'address': 'soya@kaist.ac.kr', 'verified': T...</td>\n",
       "      <td>{'fullName': 'Soya Park', 'avatar': 'http://or...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>328Ai3RCXvYfF7DPj</td>\n",
       "      <td>2019-06-17 01:54:34.941</td>\n",
       "      <td>{'password': {'bcrypt': '$2a$10$TSKpb1QRQKTVfl...</td>\n",
       "      <td>[{'address': 'nikhil07prakash@gmail.com', 'ver...</td>\n",
       "      <td>{'fullName': 'Nikhil Prakash', 'avatar': 'http...</td>\n",
       "      <td>[{'groupId': 'BibLRuKtNNv7QEDqb', 'role': {'ti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 _id               createdAt  \\\n",
       "0  3EuAwtcy65oC2v4ox 2018-05-02 15:34:32.218   \n",
       "1  3Y7RFcwRG4fyDGJBM 2018-05-02 15:35:12.612   \n",
       "2  2Lefr8WhP7DMFSbgY 2017-09-27 17:06:02.503   \n",
       "3  2HxiToJbYpPzjp22y 2016-12-09 01:55:40.646   \n",
       "4  328Ai3RCXvYfF7DPj 2019-06-17 01:54:34.941   \n",
       "\n",
       "                                            services  \\\n",
       "0                                   {'password': {}}   \n",
       "1                                   {'password': {}}   \n",
       "2  {'password': {'bcrypt': '$2a$10$djvQf78jjBEAGs...   \n",
       "3  {'password': {'bcrypt': '$2a$10$n5KHTA./KfKgM....   \n",
       "4  {'password': {'bcrypt': '$2a$10$TSKpb1QRQKTVfl...   \n",
       "\n",
       "                                              emails  \\\n",
       "0  [{'address': 'GaryBland2014@U.NORTHWESTERN.EDU...   \n",
       "1  [{'address': 'EricaMinor2015@U.NORTHWESTERN.ED...   \n",
       "2  [{'address': 'allisonlu2018@u.northwestern.edu...   \n",
       "3  [{'address': 'soya@kaist.ac.kr', 'verified': T...   \n",
       "4  [{'address': 'nikhil07prakash@gmail.com', 'ver...   \n",
       "\n",
       "                                             profile  \\\n",
       "0   {'fullName': 'GaryBland2014@U.NORTHWESTERN.EDU'}   \n",
       "1  {'fullName': 'EricaMinor2015@U.NORTHWESTERN.EDU'}   \n",
       "2  {'fullName': 'Allison Lu', 'avatar': 'http://o...   \n",
       "3  {'fullName': 'Soya Park', 'avatar': 'http://or...   \n",
       "4  {'fullName': 'Nikhil Prakash', 'avatar': 'http...   \n",
       "\n",
       "                                              groups  \n",
       "0  [{'groupId': 'TjwobnBm8xX9BTipw', 'role': {'_i...  \n",
       "1  [{'groupId': 'TjwobnBm8xX9BTipw', 'role': {'_i...  \n",
       "2  [{'groupId': 'sM3z5FkZfsABqcj3g', 'role': {'ti...  \n",
       "3                                                 []  \n",
       "4  [{'groupId': 'BibLRuKtNNv7QEDqb', 'role': {'ti...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.DataFrame(list(db.users.find({})))\n",
    "\n",
    "print(\"Number of Users: {}\".format(len(users)))\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Groups \n",
      "Original size: 847 --> New size: 183\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>groupName</th>\n",
       "      <th>description</th>\n",
       "      <th>creatorId</th>\n",
       "      <th>creatorName</th>\n",
       "      <th>creationDate</th>\n",
       "      <th>roles</th>\n",
       "      <th>members</th>\n",
       "      <th>active</th>\n",
       "      <th>activePairing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8s3BgEkMgkBTmGRJF</td>\n",
       "      <td>Future Everyday_beta</td>\n",
       "      <td>testing</td>\n",
       "      <td>YcemXAvHqLB54i5b9</td>\n",
       "      <td>Yu-Ting</td>\n",
       "      <td>2019-01-30 12:56:25.646</td>\n",
       "      <td>[{'title': 'Professor', '_id': 'qaAohZLygP6Eod...</td>\n",
       "      <td>[{'fullName': 'Yu-Ting', 'userId': 'YcemXAvHqL...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2uDCYsTKttn4zuEY9</td>\n",
       "      <td>POEM Lab</td>\n",
       "      <td>Research group at NCSU</td>\n",
       "      <td>XXHPSMLDh75odCZQp</td>\n",
       "      <td>Chris Martens</td>\n",
       "      <td>2018-01-23 18:58:35.624</td>\n",
       "      <td>[{'title': 'Professor', '_id': '6zcLDqjRofjDY5...</td>\n",
       "      <td>[{'fullName': 'Chris Martens', 'userId': 'XXHP...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NDbRpfE8cnXMfRzHc</td>\n",
       "      <td>AY18 MSC 538-0</td>\n",
       "      <td>Graduate Class: Workplace Learning &amp; Communiti...</td>\n",
       "      <td>QKt8uNR9BvNSGH3FT</td>\n",
       "      <td>Amy Hauenstein</td>\n",
       "      <td>2018-06-15 19:07:12.679</td>\n",
       "      <td>[{'title': 'Graduate Student', '_id': 'hMnM78Y...</td>\n",
       "      <td>[{'fullName': 'Amy Hauenstein', 'userId': 'QKt...</td>\n",
       "      <td>True</td>\n",
       "      <td>csrJ2ihdeMwAQdFXG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jYf6GwPb6FiJdnxfk</td>\n",
       "      <td>CROMA Lab</td>\n",
       "      <td>UMich CROMA Lab</td>\n",
       "      <td>HRb63v7L3bR4MRMbk</td>\n",
       "      <td>Stephanie O'Keefe</td>\n",
       "      <td>2017-06-28 15:48:48.594</td>\n",
       "      <td>[{'title': 'Professor', '_id': 'Dd6ronS9fnNhEG...</td>\n",
       "      <td>[{'fullName': 'Stephanie O'Keefe', 'userId': '...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g65pw3MM5TD3qCE8T</td>\n",
       "      <td>Slalom NYC D&amp;A Mentorship Group</td>\n",
       "      <td>Slalom NYC D&amp;A Mentorship Group</td>\n",
       "      <td>Rwebd6jSzjFPzFvSk</td>\n",
       "      <td>Saurabh Rane</td>\n",
       "      <td>2020-07-21 21:02:45.072</td>\n",
       "      <td>[{'title': 'Professor', '_id': 'AGY3fmpCuFG3mk...</td>\n",
       "      <td>[{'fullName': 'Saurabh Rane', 'userId': 'Rwebd...</td>\n",
       "      <td>True</td>\n",
       "      <td>girC7kwP87tRtoNR5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 _id                        groupName  \\\n",
       "0  8s3BgEkMgkBTmGRJF             Future Everyday_beta   \n",
       "1  2uDCYsTKttn4zuEY9                         POEM Lab   \n",
       "2  NDbRpfE8cnXMfRzHc                   AY18 MSC 538-0   \n",
       "3  jYf6GwPb6FiJdnxfk                        CROMA Lab   \n",
       "4  g65pw3MM5TD3qCE8T  Slalom NYC D&A Mentorship Group   \n",
       "\n",
       "                                         description          creatorId  \\\n",
       "0                                            testing  YcemXAvHqLB54i5b9   \n",
       "1                             Research group at NCSU  XXHPSMLDh75odCZQp   \n",
       "2  Graduate Class: Workplace Learning & Communiti...  QKt8uNR9BvNSGH3FT   \n",
       "3                                    UMich CROMA Lab  HRb63v7L3bR4MRMbk   \n",
       "4                    Slalom NYC D&A Mentorship Group  Rwebd6jSzjFPzFvSk   \n",
       "\n",
       "         creatorName            creationDate  \\\n",
       "0            Yu-Ting 2019-01-30 12:56:25.646   \n",
       "1      Chris Martens 2018-01-23 18:58:35.624   \n",
       "2     Amy Hauenstein 2018-06-15 19:07:12.679   \n",
       "3  Stephanie O'Keefe 2017-06-28 15:48:48.594   \n",
       "4       Saurabh Rane 2020-07-21 21:02:45.072   \n",
       "\n",
       "                                               roles  \\\n",
       "0  [{'title': 'Professor', '_id': 'qaAohZLygP6Eod...   \n",
       "1  [{'title': 'Professor', '_id': '6zcLDqjRofjDY5...   \n",
       "2  [{'title': 'Graduate Student', '_id': 'hMnM78Y...   \n",
       "3  [{'title': 'Professor', '_id': 'Dd6ronS9fnNhEG...   \n",
       "4  [{'title': 'Professor', '_id': 'AGY3fmpCuFG3mk...   \n",
       "\n",
       "                                             members  active  \\\n",
       "0  [{'fullName': 'Yu-Ting', 'userId': 'YcemXAvHqL...    True   \n",
       "1  [{'fullName': 'Chris Martens', 'userId': 'XXHP...    True   \n",
       "2  [{'fullName': 'Amy Hauenstein', 'userId': 'QKt...    True   \n",
       "3  [{'fullName': 'Stephanie O'Keefe', 'userId': '...    True   \n",
       "4  [{'fullName': 'Saurabh Rane', 'userId': 'Rwebd...    True   \n",
       "\n",
       "       activePairing  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2  csrJ2ihdeMwAQdFXG  \n",
       "3                NaN  \n",
       "4  girC7kwP87tRtoNR5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = pd.DataFrame(list(db.groups.find({})))\n",
    "\n",
    "# remove testing groups\n",
    "group_creator_ignore_list = [\n",
    "    \"Demo Admin\",\n",
    "    \"ykykykykykykykykykyk\",\n",
    "    \"Stella\",\n",
    "    \"Kevin Northwestern\",\n",
    "    \"Kevin Chen\",\n",
    "    \"Leesha\",\n",
    "    \"Jennie\",\n",
    "    \"Kapil Garg\",\n",
    "]\n",
    "group_ignore_ids = groups[groups[\"creatorName\"].isin(group_creator_ignore_list)][\n",
    "    \"_id\"\n",
    "].unique()\n",
    "\n",
    "# subset groups by id\n",
    "groups_orig_size = len(groups)\n",
    "groups_new_size = 0\n",
    "\n",
    "groups = groups[~groups[\"_id\"].isin(group_ignore_ids)]\n",
    "groups.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# print change in size\n",
    "groups_new_size = len(groups)\n",
    "print(\n",
    "    \"Number of Groups \\nOriginal size: {} --> New size: {}\".format(\n",
    "        groups_orig_size, groups_new_size\n",
    "    )\n",
    ")\n",
    "\n",
    "# display task history\n",
    "groups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tasks\n",
      "Original size: 8349 --> New size: 8302\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>name</th>\n",
       "      <th>userId</th>\n",
       "      <th>groupId</th>\n",
       "      <th>task</th>\n",
       "      <th>pairingId</th>\n",
       "      <th>group_pairing_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2AYpCGrankHaLTuTN</td>\n",
       "      <td>Yongsung Kim</td>\n",
       "      <td>EDEFWcagLwCfXP5Jg</td>\n",
       "      <td>9mdkMmj4pY8Q2TwqF</td>\n",
       "      <td>i need to help with quarterly/yearly plan</td>\n",
       "      <td>Hje6thvxpudhfy6C5</td>\n",
       "      <td>9mdkMmj4pY8Q2TwqF-Hje6thvxpudhfy6C5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2Gi7xcv8NDzQRGJdC</td>\n",
       "      <td>Yongsung Kim</td>\n",
       "      <td>6vpLhKvhfxn9vKP2f</td>\n",
       "      <td>5QXWCwAFBrdbLYGar</td>\n",
       "      <td>I need to recruit a lot of people (30-40) who ...</td>\n",
       "      <td>QEvCZCAQeE4WJuhAE</td>\n",
       "      <td>5QXWCwAFBrdbLYGar-QEvCZCAQeE4WJuhAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23NBmRrQCWcyLWtFE</td>\n",
       "      <td>Kristine Lu</td>\n",
       "      <td>xQ4mPiD4TX9MJqiqj</td>\n",
       "      <td>9mdkMmj4pY8Q2TwqF</td>\n",
       "      <td>Hold me accountable for writing another iterat...</td>\n",
       "      <td>QLv7Kd3NFjstGYQ25</td>\n",
       "      <td>9mdkMmj4pY8Q2TwqF-QLv7Kd3NFjstGYQ25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2Cj9cgw74Xbj4ffEn</td>\n",
       "      <td>Bomani McClendon</td>\n",
       "      <td>u6DrqFSvdZnWDgjz8</td>\n",
       "      <td>sM3z5FkZfsABqcj3g</td>\n",
       "      <td>Meteor Tech Help: How to deal with async getti...</td>\n",
       "      <td>9cSpnw4oMBgvCf6gz</td>\n",
       "      <td>sM3z5FkZfsABqcj3g-9cSpnw4oMBgvCf6gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2NwuggEdhbPHyt9a2</td>\n",
       "      <td>Stephanie Jones</td>\n",
       "      <td>QiiDySM5ehXjLoNRL</td>\n",
       "      <td>KaYHdgPnyHQx84CPL</td>\n",
       "      <td>Life</td>\n",
       "      <td>KDAzB3MBJfXPZRTTA</td>\n",
       "      <td>KaYHdgPnyHQx84CPL-KDAzB3MBJfXPZRTTA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 _id              name             userId            groupId  \\\n",
       "0  2AYpCGrankHaLTuTN      Yongsung Kim  EDEFWcagLwCfXP5Jg  9mdkMmj4pY8Q2TwqF   \n",
       "1  2Gi7xcv8NDzQRGJdC      Yongsung Kim  6vpLhKvhfxn9vKP2f  5QXWCwAFBrdbLYGar   \n",
       "2  23NBmRrQCWcyLWtFE       Kristine Lu  xQ4mPiD4TX9MJqiqj  9mdkMmj4pY8Q2TwqF   \n",
       "3  2Cj9cgw74Xbj4ffEn  Bomani McClendon  u6DrqFSvdZnWDgjz8  sM3z5FkZfsABqcj3g   \n",
       "4  2NwuggEdhbPHyt9a2   Stephanie Jones  QiiDySM5ehXjLoNRL  KaYHdgPnyHQx84CPL   \n",
       "\n",
       "                                                task          pairingId  \\\n",
       "0          i need to help with quarterly/yearly plan  Hje6thvxpudhfy6C5   \n",
       "1  I need to recruit a lot of people (30-40) who ...  QEvCZCAQeE4WJuhAE   \n",
       "2  Hold me accountable for writing another iterat...  QLv7Kd3NFjstGYQ25   \n",
       "3  Meteor Tech Help: How to deal with async getti...  9cSpnw4oMBgvCf6gz   \n",
       "4                                               Life  KDAzB3MBJfXPZRTTA   \n",
       "\n",
       "                      group_pairing_id  \n",
       "0  9mdkMmj4pY8Q2TwqF-Hje6thvxpudhfy6C5  \n",
       "1  5QXWCwAFBrdbLYGar-QEvCZCAQeE4WJuhAE  \n",
       "2  9mdkMmj4pY8Q2TwqF-QLv7Kd3NFjstGYQ25  \n",
       "3  sM3z5FkZfsABqcj3g-9cSpnw4oMBgvCf6gz  \n",
       "4  KaYHdgPnyHQx84CPL-KDAzB3MBJfXPZRTTA  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks_history = pd.DataFrame(list(db.tasks_history.find({})))\n",
    "\n",
    "# remove bad groups\n",
    "tasks_history_orig_size = len(tasks_history)\n",
    "tasks_history_new_size = 0\n",
    "\n",
    "tasks_history = tasks_history[~tasks_history[\"groupId\"].isin(group_ignore_ids)]\n",
    "tasks_history.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# add group_pairing_id\n",
    "tasks_history[\"group_pairing_id\"] = (\n",
    "    tasks_history[\"groupId\"] + \"-\" + tasks_history[\"pairingId\"]\n",
    ")\n",
    "\n",
    "# print change in size\n",
    "tasks_history_new_size = len(tasks_history)\n",
    "print(\n",
    "    \"Number of Tasks\\nOriginal size: {} --> New size: {}\".format(\n",
    "        tasks_history_orig_size, tasks_history_new_size\n",
    "    )\n",
    ")\n",
    "\n",
    "# display task history\n",
    "tasks_history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Pairing Sessions\n",
      "Original size: 1148 --> New size: 1055\n",
      "Pairing count: 1055, Unique group count: 101\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>groupId</th>\n",
       "      <th>pairings</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group_pairing_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>jEFzQKHgftXeHhsfu</td>\n",
       "      <td>3HSsYKw5m2CrAZtFs</td>\n",
       "      <td>[{'firstUserId': 'f5Q6ebhramRfx7GQR', 'firstUs...</td>\n",
       "      <td>2025-09-25 08:32:51.549</td>\n",
       "      <td>3HSsYKw5m2CrAZtFs-jEFzQKHgftXeHhsfu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>jMBRdqYugAc5Y7NbG</td>\n",
       "      <td>3HSsYKw5m2CrAZtFs</td>\n",
       "      <td>[{'firstUserId': 'd9T3ZrcKMRvi6kqih', 'firstUs...</td>\n",
       "      <td>2025-09-18 09:39:22.754</td>\n",
       "      <td>3HSsYKw5m2CrAZtFs-jMBRdqYugAc5Y7NbG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>LrvQ6xQfRzvjxSy9F</td>\n",
       "      <td>9mdkMmj4pY8Q2TwqF</td>\n",
       "      <td>[{'firstUserId': 'Tmp7YeTw5ohABj8uK', 'firstUs...</td>\n",
       "      <td>2025-01-28 03:29:44.408</td>\n",
       "      <td>9mdkMmj4pY8Q2TwqF-LrvQ6xQfRzvjxSy9F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>PFZGAFC2RL6X3Q7qQ</td>\n",
       "      <td>9mdkMmj4pY8Q2TwqF</td>\n",
       "      <td>[{'firstUserId': 'z5uM74YSjK5KEXYGC', 'firstUs...</td>\n",
       "      <td>2025-01-28 03:29:42.907</td>\n",
       "      <td>9mdkMmj4pY8Q2TwqF-PFZGAFC2RL6X3Q7qQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>GpkZoHZo6BrFuKSCg</td>\n",
       "      <td>zakxD2tAeS5JEFPKx</td>\n",
       "      <td>[{'firstUserId': 't8KcY69e6ddKo7qRJ', 'firstUs...</td>\n",
       "      <td>2024-10-30 21:43:17.896</td>\n",
       "      <td>zakxD2tAeS5JEFPKx-GpkZoHZo6BrFuKSCg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    _id            groupId  \\\n",
       "1054  jEFzQKHgftXeHhsfu  3HSsYKw5m2CrAZtFs   \n",
       "1053  jMBRdqYugAc5Y7NbG  3HSsYKw5m2CrAZtFs   \n",
       "1052  LrvQ6xQfRzvjxSy9F  9mdkMmj4pY8Q2TwqF   \n",
       "1051  PFZGAFC2RL6X3Q7qQ  9mdkMmj4pY8Q2TwqF   \n",
       "1050  GpkZoHZo6BrFuKSCg  zakxD2tAeS5JEFPKx   \n",
       "\n",
       "                                               pairings  \\\n",
       "1054  [{'firstUserId': 'f5Q6ebhramRfx7GQR', 'firstUs...   \n",
       "1053  [{'firstUserId': 'd9T3ZrcKMRvi6kqih', 'firstUs...   \n",
       "1052  [{'firstUserId': 'Tmp7YeTw5ohABj8uK', 'firstUs...   \n",
       "1051  [{'firstUserId': 'z5uM74YSjK5KEXYGC', 'firstUs...   \n",
       "1050  [{'firstUserId': 't8KcY69e6ddKo7qRJ', 'firstUs...   \n",
       "\n",
       "                   timestamp                     group_pairing_id  \n",
       "1054 2025-09-25 08:32:51.549  3HSsYKw5m2CrAZtFs-jEFzQKHgftXeHhsfu  \n",
       "1053 2025-09-18 09:39:22.754  3HSsYKw5m2CrAZtFs-jMBRdqYugAc5Y7NbG  \n",
       "1052 2025-01-28 03:29:44.408  9mdkMmj4pY8Q2TwqF-LrvQ6xQfRzvjxSy9F  \n",
       "1051 2025-01-28 03:29:42.907  9mdkMmj4pY8Q2TwqF-PFZGAFC2RL6X3Q7qQ  \n",
       "1050 2024-10-30 21:43:17.896  zakxD2tAeS5JEFPKx-GpkZoHZo6BrFuKSCg  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairings = pd.DataFrame(list(db.pairings.find({})))\n",
    "\n",
    "# remove bad groups\n",
    "pairings_orig_size = len(pairings)\n",
    "pairings_new_size = 0\n",
    "\n",
    "pairings = pairings[~pairings[\"groupId\"].isin(group_ignore_ids)]\n",
    "\n",
    "# add group_pair id\n",
    "pairings[\"group_pairing_id\"] = pairings[\"groupId\"] + \"-\" + pairings[\"_id\"]\n",
    "pairings.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# print change in size\n",
    "pairings_new_size = len(pairings)\n",
    "print(\n",
    "    \"Number of Pairing Sessions\\nOriginal size: {} --> New size: {}\".format(\n",
    "        pairings_orig_size, pairings_new_size\n",
    "    )\n",
    ")\n",
    "\n",
    "# display current pairings\n",
    "print(\n",
    "    \"Pairing count: {}, Unique group count: {}\".format(\n",
    "        len(pairings), len(pairings.groupId.unique())\n",
    "    )\n",
    ")\n",
    "pairings.sort_values(\"timestamp\", ascending=False, inplace=True)\n",
    "pairings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Pairs\n",
      "Original size: 5319 --> New size: 5288\n",
      "Unique group count: 101, Unique pairing count: 1055\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>groupId</th>\n",
       "      <th>pairingId</th>\n",
       "      <th>firstUserId</th>\n",
       "      <th>firstUserName</th>\n",
       "      <th>firstUserRole</th>\n",
       "      <th>secondUserId</th>\n",
       "      <th>secondUserName</th>\n",
       "      <th>secondUserRole</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group_pairing_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5287</th>\n",
       "      <td>E22H5DgSJLMje4kgK</td>\n",
       "      <td>3HSsYKw5m2CrAZtFs</td>\n",
       "      <td>jEFzQKHgftXeHhsfu</td>\n",
       "      <td>d9T3ZrcKMRvi6kqih</td>\n",
       "      <td>Gus Umbelino</td>\n",
       "      <td>Post Doc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-09-25 08:32:51.549</td>\n",
       "      <td>3HSsYKw5m2CrAZtFs-jEFzQKHgftXeHhsfu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5286</th>\n",
       "      <td>gDzBoHRZ2ZH9A7YtL</td>\n",
       "      <td>3HSsYKw5m2CrAZtFs</td>\n",
       "      <td>jEFzQKHgftXeHhsfu</td>\n",
       "      <td>f5Q6ebhramRfx7GQR</td>\n",
       "      <td>M. Piano</td>\n",
       "      <td>Graduate Student</td>\n",
       "      <td>8D2ax9LuSi39d3qyC</td>\n",
       "      <td>Irina Lehner</td>\n",
       "      <td>Graduate Student</td>\n",
       "      <td>2025-09-25 08:32:51.549</td>\n",
       "      <td>3HSsYKw5m2CrAZtFs-jEFzQKHgftXeHhsfu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5285</th>\n",
       "      <td>ZJnJ4y73xFNFKYAMz</td>\n",
       "      <td>3HSsYKw5m2CrAZtFs</td>\n",
       "      <td>jMBRdqYugAc5Y7NbG</td>\n",
       "      <td>d9T3ZrcKMRvi6kqih</td>\n",
       "      <td>Gus Umbelino</td>\n",
       "      <td>Post Doc</td>\n",
       "      <td>NuJFYbray3MW4jQoC</td>\n",
       "      <td>Stefan Kalberer</td>\n",
       "      <td>Graduate Student</td>\n",
       "      <td>2025-09-18 09:39:22.754</td>\n",
       "      <td>3HSsYKw5m2CrAZtFs-jMBRdqYugAc5Y7NbG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5284</th>\n",
       "      <td>KgEpi95JnzE29HxDe</td>\n",
       "      <td>9mdkMmj4pY8Q2TwqF</td>\n",
       "      <td>LrvQ6xQfRzvjxSy9F</td>\n",
       "      <td>Tmp7YeTw5ohABj8uK</td>\n",
       "      <td>Yinmiao Li</td>\n",
       "      <td>PhD Student</td>\n",
       "      <td>z5uM74YSjK5KEXYGC</td>\n",
       "      <td>Melissa Chen</td>\n",
       "      <td>PhD Student</td>\n",
       "      <td>2025-01-28 03:29:44.408</td>\n",
       "      <td>9mdkMmj4pY8Q2TwqF-LrvQ6xQfRzvjxSy9F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5283</th>\n",
       "      <td>RRbwvkSMAPwnAEAkn</td>\n",
       "      <td>9mdkMmj4pY8Q2TwqF</td>\n",
       "      <td>PFZGAFC2RL6X3Q7qQ</td>\n",
       "      <td>z5uM74YSjK5KEXYGC</td>\n",
       "      <td>Melissa Chen</td>\n",
       "      <td>PhD Student</td>\n",
       "      <td>Tmp7YeTw5ohABj8uK</td>\n",
       "      <td>Yinmiao Li</td>\n",
       "      <td>PhD Student</td>\n",
       "      <td>2025-01-28 03:29:42.907</td>\n",
       "      <td>9mdkMmj4pY8Q2TwqF-PFZGAFC2RL6X3Q7qQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    _id            groupId          pairingId  \\\n",
       "5287  E22H5DgSJLMje4kgK  3HSsYKw5m2CrAZtFs  jEFzQKHgftXeHhsfu   \n",
       "5286  gDzBoHRZ2ZH9A7YtL  3HSsYKw5m2CrAZtFs  jEFzQKHgftXeHhsfu   \n",
       "5285  ZJnJ4y73xFNFKYAMz  3HSsYKw5m2CrAZtFs  jMBRdqYugAc5Y7NbG   \n",
       "5284  KgEpi95JnzE29HxDe  9mdkMmj4pY8Q2TwqF  LrvQ6xQfRzvjxSy9F   \n",
       "5283  RRbwvkSMAPwnAEAkn  9mdkMmj4pY8Q2TwqF  PFZGAFC2RL6X3Q7qQ   \n",
       "\n",
       "            firstUserId firstUserName     firstUserRole       secondUserId  \\\n",
       "5287  d9T3ZrcKMRvi6kqih  Gus Umbelino          Post Doc                NaN   \n",
       "5286  f5Q6ebhramRfx7GQR      M. Piano  Graduate Student  8D2ax9LuSi39d3qyC   \n",
       "5285  d9T3ZrcKMRvi6kqih  Gus Umbelino          Post Doc  NuJFYbray3MW4jQoC   \n",
       "5284  Tmp7YeTw5ohABj8uK    Yinmiao Li       PhD Student  z5uM74YSjK5KEXYGC   \n",
       "5283  z5uM74YSjK5KEXYGC  Melissa Chen       PhD Student  Tmp7YeTw5ohABj8uK   \n",
       "\n",
       "       secondUserName    secondUserRole               timestamp  \\\n",
       "5287              NaN               NaN 2025-09-25 08:32:51.549   \n",
       "5286     Irina Lehner  Graduate Student 2025-09-25 08:32:51.549   \n",
       "5285  Stefan Kalberer  Graduate Student 2025-09-18 09:39:22.754   \n",
       "5284     Melissa Chen       PhD Student 2025-01-28 03:29:44.408   \n",
       "5283       Yinmiao Li       PhD Student 2025-01-28 03:29:42.907   \n",
       "\n",
       "                         group_pairing_id  \n",
       "5287  3HSsYKw5m2CrAZtFs-jEFzQKHgftXeHhsfu  \n",
       "5286  3HSsYKw5m2CrAZtFs-jEFzQKHgftXeHhsfu  \n",
       "5285  3HSsYKw5m2CrAZtFs-jMBRdqYugAc5Y7NbG  \n",
       "5284  9mdkMmj4pY8Q2TwqF-LrvQ6xQfRzvjxSy9F  \n",
       "5283  9mdkMmj4pY8Q2TwqF-PFZGAFC2RL6X3Q7qQ  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_history = pd.DataFrame(list(db.pairs_history.find({})))\n",
    "\n",
    "# remove bad groups\n",
    "pairs_history_orig_size = len(pairs_history)\n",
    "pairs_history_new_size = 0\n",
    "\n",
    "pairs_history = pairs_history[~pairs_history[\"groupId\"].isin(group_ignore_ids)]\n",
    "\n",
    "# add group_pairing_id column\n",
    "pairs_history[\"group_pairing_id\"] = (\n",
    "    pairs_history[\"groupId\"] + \"-\" + pairs_history[\"pairingId\"]\n",
    ")\n",
    "pairs_history.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# print change in size\n",
    "pairs_history_new_size = len(pairs_history)\n",
    "print(\n",
    "    \"Number of Pairs\\nOriginal size: {} --> New size: {}\".format(\n",
    "        pairs_history_orig_size, pairs_history_new_size\n",
    "    )\n",
    ")\n",
    "\n",
    "# display current pairs_history\n",
    "print(\n",
    "    \"Unique group count: {}, Unique pairing count: {}\".format(\n",
    "        len(pairs_history.groupId.unique()),\n",
    "        len(pairs_history.group_pairing_id.unique()),\n",
    "    )\n",
    ")\n",
    "pairs_history.sort_values(\"timestamp\", ascending=False, inplace=True)\n",
    "pairs_history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tasks\n",
      "Original size: 1638 --> New size: 1439\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>name</th>\n",
       "      <th>userId</th>\n",
       "      <th>groupId</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2QsjYvvBF59JvBq3y</td>\n",
       "      <td>Haoqi</td>\n",
       "      <td>P7EHknAnmFM3c5iXC</td>\n",
       "      <td>awCE87hpPLm3Hpyvq</td>\n",
       "      <td>Abc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6SWWJDq2Ku4YCx2d4</td>\n",
       "      <td>moliri</td>\n",
       "      <td>5QiYq9AN8CEPgWMkp</td>\n",
       "      <td>9bBK7o9t2nAqNjc4W</td>\n",
       "      <td>hihi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6gBn9ej23BMBgrWSb</td>\n",
       "      <td>Kevin</td>\n",
       "      <td>pApKBgCknH8dspddZ</td>\n",
       "      <td>qe3ip9Zspigz8mWve</td>\n",
       "      <td>thing!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MDCMw8XTCb8DTk64H</td>\n",
       "      <td>Luke S Murray</td>\n",
       "      <td>ZFCNCYSqfXtGigZjZ</td>\n",
       "      <td>XcEPz3nJaEfHGhn6x</td>\n",
       "      <td>review my incomplete related works</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nszt5do4pqafRLSCZ</td>\n",
       "      <td>David Karger</td>\n",
       "      <td>W8RgxxQM5k2kKLNZD</td>\n",
       "      <td>Ywbg3AeBPfzbAB74z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 _id           name             userId            groupId  \\\n",
       "0  2QsjYvvBF59JvBq3y          Haoqi  P7EHknAnmFM3c5iXC  awCE87hpPLm3Hpyvq   \n",
       "1  6SWWJDq2Ku4YCx2d4         moliri  5QiYq9AN8CEPgWMkp  9bBK7o9t2nAqNjc4W   \n",
       "2  6gBn9ej23BMBgrWSb          Kevin  pApKBgCknH8dspddZ  qe3ip9Zspigz8mWve   \n",
       "3  MDCMw8XTCb8DTk64H  Luke S Murray  ZFCNCYSqfXtGigZjZ  XcEPz3nJaEfHGhn6x   \n",
       "4  Nszt5do4pqafRLSCZ   David Karger  W8RgxxQM5k2kKLNZD  Ywbg3AeBPfzbAB74z   \n",
       "\n",
       "                                 task  \n",
       "0                                 Abc  \n",
       "1                                hihi  \n",
       "2                              thing!  \n",
       "3  review my incomplete related works  \n",
       "4                                 NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks = pd.DataFrame(list(db.tasks.find({})))\n",
    "\n",
    "# remove bad groups\n",
    "tasks_orig_size = len(tasks)\n",
    "tasks_new_size = 0\n",
    "\n",
    "tasks = tasks[~tasks[\"groupId\"].isin(group_ignore_ids)]\n",
    "tasks.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# print change in size\n",
    "tasks_new_size = len(tasks)\n",
    "print(\n",
    "    \"Number of Tasks\\nOriginal size: {} --> New size: {}\".format(\n",
    "        tasks_orig_size, tasks_new_size\n",
    "    )\n",
    ")\n",
    "\n",
    "# display current tasks\n",
    "tasks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Current Affinities\n",
      "Original size: 5178 --> New size: 5135\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>helperId</th>\n",
       "      <th>helpeeId</th>\n",
       "      <th>groupId</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2ftfXQtMgAAiczLJZ</td>\n",
       "      <td>PavTL8zD9664wvtfB</td>\n",
       "      <td>y5D7YfEuTMh8WaFzx</td>\n",
       "      <td>qPnf2DHHihugATnxD</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34CtrtqTv6MQ8vxaF</td>\n",
       "      <td>p9MttJyv3nigGjYqx</td>\n",
       "      <td>ZiE5NmwE3Q2LmiKmS</td>\n",
       "      <td>LXsBj4mnCKbkYJmAX</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2rkCWfsxNvzauqLx9</td>\n",
       "      <td>PkuiEYaGwChXy3LL6</td>\n",
       "      <td>MEsDmc4AeaAQ44RQL</td>\n",
       "      <td>NDbRpfE8cnXMfRzHc</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>245JFYNd6XNwk5nbd</td>\n",
       "      <td>acoFQ6xXo29zBPcPp</td>\n",
       "      <td>kMEKB25ouoW8nM5JP</td>\n",
       "      <td>u4kjJC55DPMLpR8bC</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2mjBwESgcvCcLZKb9</td>\n",
       "      <td>BdMQjxPpYw7ELEf3B</td>\n",
       "      <td>Jfk5kDRyPjnLaWpjD</td>\n",
       "      <td>ko6giLvq9cE842rHY</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 _id           helperId           helpeeId            groupId  \\\n",
       "0  2ftfXQtMgAAiczLJZ  PavTL8zD9664wvtfB  y5D7YfEuTMh8WaFzx  qPnf2DHHihugATnxD   \n",
       "1  34CtrtqTv6MQ8vxaF  p9MttJyv3nigGjYqx  ZiE5NmwE3Q2LmiKmS  LXsBj4mnCKbkYJmAX   \n",
       "2  2rkCWfsxNvzauqLx9  PkuiEYaGwChXy3LL6  MEsDmc4AeaAQ44RQL  NDbRpfE8cnXMfRzHc   \n",
       "3  245JFYNd6XNwk5nbd  acoFQ6xXo29zBPcPp  kMEKB25ouoW8nM5JP  u4kjJC55DPMLpR8bC   \n",
       "4  2mjBwESgcvCcLZKb9  BdMQjxPpYw7ELEf3B  Jfk5kDRyPjnLaWpjD  ko6giLvq9cE842rHY   \n",
       "\n",
       "   value  \n",
       "0   1.00  \n",
       "1   2.00  \n",
       "2  -1.00  \n",
       "3   0.33  \n",
       "4   5.00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affinities = pd.DataFrame(list(db.affinities.find({})))\n",
    "\n",
    "# remove bad groups\n",
    "affinities_orig_size = len(affinities)\n",
    "affinities_new_size = 0\n",
    "\n",
    "affinities = affinities[~affinities[\"groupId\"].isin(group_ignore_ids)]\n",
    "affinities.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# print change in size\n",
    "affinities_new_size = len(affinities)\n",
    "print(\n",
    "    \"Number of Current Affinities\\nOriginal size: {} --> New size: {}\".format(\n",
    "        affinities_orig_size, affinities_new_size\n",
    "    )\n",
    ")\n",
    "\n",
    "# display current affinities\n",
    "affinities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Past Affinities\n",
      "Original size: 89249 --> New size: 88612\n",
      "Unique Group Pairings: 1029\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>helperId</th>\n",
       "      <th>helpeeId</th>\n",
       "      <th>groupId</th>\n",
       "      <th>value</th>\n",
       "      <th>pairingId</th>\n",
       "      <th>group_pairing_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t29KL7evKrKmAc68s</td>\n",
       "      <td>SRrbNxcTrirkSbowD</td>\n",
       "      <td>2y7tESxwQFwro8Jca</td>\n",
       "      <td>27syMcotb279YaP2u</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3G6iXFybGhQdsjDct</td>\n",
       "      <td>27syMcotb279YaP2u-3G6iXFybGhQdsjDct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gER5DYezCoLibfHdz</td>\n",
       "      <td>sanGBbAp7tXpTMfHN</td>\n",
       "      <td>2y7tESxwQFwro8Jca</td>\n",
       "      <td>27syMcotb279YaP2u</td>\n",
       "      <td>0.33</td>\n",
       "      <td>3G6iXFybGhQdsjDct</td>\n",
       "      <td>27syMcotb279YaP2u-3G6iXFybGhQdsjDct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aThjZHs8Y8zqkuDab</td>\n",
       "      <td>2y7tESxwQFwro8Jca</td>\n",
       "      <td>66PYzPiXdpro84gaR</td>\n",
       "      <td>27syMcotb279YaP2u</td>\n",
       "      <td>0.33</td>\n",
       "      <td>3G6iXFybGhQdsjDct</td>\n",
       "      <td>27syMcotb279YaP2u-3G6iXFybGhQdsjDct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uJBpNF6f2Tn8a5e9Y</td>\n",
       "      <td>SRrbNxcTrirkSbowD</td>\n",
       "      <td>66PYzPiXdpro84gaR</td>\n",
       "      <td>27syMcotb279YaP2u</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3G6iXFybGhQdsjDct</td>\n",
       "      <td>27syMcotb279YaP2u-3G6iXFybGhQdsjDct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dr7Gh7q2tj4MhHmdF</td>\n",
       "      <td>sanGBbAp7tXpTMfHN</td>\n",
       "      <td>66PYzPiXdpro84gaR</td>\n",
       "      <td>27syMcotb279YaP2u</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3G6iXFybGhQdsjDct</td>\n",
       "      <td>27syMcotb279YaP2u-3G6iXFybGhQdsjDct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 _id           helperId           helpeeId            groupId  \\\n",
       "0  t29KL7evKrKmAc68s  SRrbNxcTrirkSbowD  2y7tESxwQFwro8Jca  27syMcotb279YaP2u   \n",
       "1  gER5DYezCoLibfHdz  sanGBbAp7tXpTMfHN  2y7tESxwQFwro8Jca  27syMcotb279YaP2u   \n",
       "2  aThjZHs8Y8zqkuDab  2y7tESxwQFwro8Jca  66PYzPiXdpro84gaR  27syMcotb279YaP2u   \n",
       "3  uJBpNF6f2Tn8a5e9Y  SRrbNxcTrirkSbowD  66PYzPiXdpro84gaR  27syMcotb279YaP2u   \n",
       "4  Dr7Gh7q2tj4MhHmdF  sanGBbAp7tXpTMfHN  66PYzPiXdpro84gaR  27syMcotb279YaP2u   \n",
       "\n",
       "   value          pairingId                     group_pairing_id  \n",
       "0  -1.00  3G6iXFybGhQdsjDct  27syMcotb279YaP2u-3G6iXFybGhQdsjDct  \n",
       "1   0.33  3G6iXFybGhQdsjDct  27syMcotb279YaP2u-3G6iXFybGhQdsjDct  \n",
       "2   0.33  3G6iXFybGhQdsjDct  27syMcotb279YaP2u-3G6iXFybGhQdsjDct  \n",
       "3  -1.00  3G6iXFybGhQdsjDct  27syMcotb279YaP2u-3G6iXFybGhQdsjDct  \n",
       "4  -1.00  3G6iXFybGhQdsjDct  27syMcotb279YaP2u-3G6iXFybGhQdsjDct  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affinities_history = pd.DataFrame(list(db.affinities_history.find({})))\n",
    "\n",
    "# remove bad groups\n",
    "affinities_history_orig_size = len(affinities_history)\n",
    "affinities_history_new_size = 0\n",
    "\n",
    "affinities_history = affinities_history[\n",
    "    ~affinities_history[\"groupId\"].isin(group_ignore_ids)\n",
    "]\n",
    "\n",
    "# add group_pairing_id column\n",
    "affinities_history[\"group_pairing_id\"] = (\n",
    "    affinities_history[\"groupId\"] + \"-\" + affinities_history[\"pairingId\"]\n",
    ")\n",
    "\n",
    "# remove duplicate ratings\n",
    "affinities_history.sort_values(\n",
    "    [\"group_pairing_id\", \"helpeeId\", \"helperId\"], inplace=True\n",
    ")\n",
    "affinities_history.drop_duplicates(\n",
    "    subset=[\"group_pairing_id\", \"helpeeId\", \"helperId\"], keep=\"last\", inplace=True\n",
    ")\n",
    "affinities_history.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# print change in size\n",
    "affinities_history_new_size = len(affinities_history)\n",
    "print(\n",
    "    \"Number of Past Affinities\\nOriginal size: {} --> New size: {}\".format(\n",
    "        affinities_history_orig_size, affinities_history_new_size\n",
    "    )\n",
    ")\n",
    "\n",
    "# display affinity data\n",
    "print(\n",
    "    \"Unique Group Pairings: {}\".format(\n",
    "        len(affinities_history.group_pairing_id.unique())\n",
    "    )\n",
    ")\n",
    "affinities_history.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Stable Matching with All Previous Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_affinity_matrix(input_affinities, tasks):\n",
    "    \"\"\"\n",
    "    Creates an n^2 affinity matrix.\n",
    "\n",
    "    Input:\n",
    "        input_affinities (pandas DataFrame): dataframe with helpeeId, helperId, and value columns.\n",
    "        tasks (pandas DataFrame): current tasks for pairing. used to create superset of users in event some don't rate any others.\n",
    "\n",
    "    Output:\n",
    "        (list of list of numbers): matrix of affinities. 0 if no affinity between users.\n",
    "        (dict): dict where keys are numbers and values are userIds mapping matrix index to users.\n",
    "    \"\"\"\n",
    "    # dont modify original dataframe\n",
    "    affinities = deepcopy(input_affinities)\n",
    "    affinities.drop_duplicates(keep=\"last\", inplace=True)\n",
    "\n",
    "    # create user superset and user:index mapping\n",
    "    user_superset = list(\n",
    "        set(\n",
    "            affinities[\"helperId\"].tolist()\n",
    "            + affinities[\"helpeeId\"].tolist()\n",
    "            + tasks[\"userId\"].tolist()\n",
    "        )\n",
    "    )\n",
    "    user_count = len(user_superset)\n",
    "    user_index_dict = {user_superset[x]: x for x in range(user_count)}\n",
    "\n",
    "    # create empty n^2 matrix\n",
    "    affinity_matrix = [[0 for y in range(user_count)] for x in range(user_count)]\n",
    "\n",
    "    # loop through data and populate matrix\n",
    "    for index, row in affinities.iterrows():\n",
    "        curr_helper_index = user_index_dict[row[\"helperId\"]]\n",
    "        curr_helpee_index = user_index_dict[row[\"helpeeId\"]]\n",
    "        curr_value = row[\"value\"]\n",
    "\n",
    "        affinity_matrix[curr_helper_index][curr_helpee_index] = curr_value\n",
    "\n",
    "    # flip user and index in dict\n",
    "    index_user_dict = {str(v): k for (k, v) in user_index_dict.items()}\n",
    "\n",
    "    return affinity_matrix, index_user_dict\n",
    "\n",
    "\n",
    "def create_pairing_dict(user_index_dict, pairing):\n",
    "    \"\"\"\n",
    "    Creates a pairing dictionary based on previous pairing, ignoring unmatched users.\n",
    "\n",
    "    Input:\n",
    "        user_index_dict (dict): mapping from users in data to indices (1-indexed)\n",
    "        pairing (list): list of pairings\n",
    "\n",
    "    Output:\n",
    "        (dict): dict containing bi-directional pairings from the pairing list with keys and values being numbers\n",
    "            ex. { '1': '2', '2': '1'}\n",
    "    \"\"\"\n",
    "    pairing_dict = {}\n",
    "    for pairs in pairing:\n",
    "        # only include cases where users are matched to one another (i.e. ignore odd people paired with -1)\n",
    "        if \"secondUserId\" in pairs:\n",
    "            # bi-directional representation in dictionary\n",
    "            pairing_dict[user_index_dict[pairs[\"firstUserId\"]]] = user_index_dict[\n",
    "                pairs[\"secondUserId\"]\n",
    "            ]\n",
    "            pairing_dict[user_index_dict[pairs[\"secondUserId\"]]] = user_index_dict[\n",
    "                pairs[\"firstUserId\"]\n",
    "            ]\n",
    "\n",
    "    return pairing_dict\n",
    "\n",
    "\n",
    "def get_recent_pairings(group_pair_id, limit):\n",
    "    \"\"\"\n",
    "    Retrieve the most recent pairings for a group_id, up to limit, before pairing instance is run\n",
    "        and return as a dictionary.\n",
    "\n",
    "    Input:\n",
    "        group_pair_id (string): group-pairing instance to get recent pairing data for.\n",
    "        limit (number): number of most recent pairings to get.\n",
    "\n",
    "    Output:\n",
    "        (dict): dict mapping, bi-directionally, each pairing\n",
    "    \"\"\"\n",
    "    group_id = group_pair_id.split(\"-\")[0]\n",
    "\n",
    "    # get timestamp of current pairing instance\n",
    "    curr_timestamp = pairings[pairings.group_pairing_id == group_pair_id].iat[\n",
    "        0, pairings.columns.get_loc(\"timestamp\")\n",
    "    ]\n",
    "\n",
    "    # get pairs for group_id that occurred before group_pair_id did and also ignore group_pair_id\n",
    "    relevant_pairings = pairings[\n",
    "        (pairings[\"groupId\"] == group_id)\n",
    "        & (pairings[\"timestamp\"] <= curr_timestamp)\n",
    "        & (pairings[\"group_pairing_id\"] != group_pair_id)\n",
    "    ]\n",
    "    pairing_instance_list = relevant_pairings.sort_values(\"timestamp\", ascending=False)[\n",
    "        0:limit\n",
    "    ][\"pairings\"].tolist()\n",
    "    output_list = []\n",
    "\n",
    "    # create dictionaries and add to output\n",
    "    for pairing_instance in pairing_instance_list:\n",
    "        pairing_dict = {}\n",
    "        for pairing in pairing_instance:\n",
    "            # check if the user is paired with someone\n",
    "            if \"secondUserId\" in pairing:\n",
    "                # bi-directional representation in dictionary\n",
    "                pairing_dict[pairing[\"firstUserId\"]] = pairing[\"secondUserId\"]\n",
    "                pairing_dict[pairing[\"secondUserId\"]] = pairing[\"firstUserId\"]\n",
    "            else:\n",
    "                pairing_dict[pairing[\"firstUserId\"]] = \"\"\n",
    "\n",
    "        # add to output list\n",
    "        output_list.append(pairing_dict)\n",
    "\n",
    "    return output_list\n",
    "\n",
    "\n",
    "def create_directed_graph(affinity_matrix, index_user_mapping, recent_pairings):\n",
    "    \"\"\"\n",
    "    Converts an affinity matrix into a weighted matrix that represented a directed graph.\n",
    "        Weight is calculated based on previous recent pairings and some random perturbation.\n",
    "\n",
    "    Input:\n",
    "        affinity_matrix (list of list of numbers): matrix of affinities. 0 if no affinity between users.\n",
    "        index_user_mapping (dict): dict where keys are numbers and values are userIds mapping matrix index to users.\n",
    "        recent_pairings (list of dict): up to 3 pairing sessions, ordered by recency,\n",
    "            with each dict containing helper-helpee pairs\n",
    "\n",
    "    Output:\n",
    "        (list of list of numbers): weighted matrix\n",
    "    \"\"\"\n",
    "    # dont modify original dataframe\n",
    "    directed_graph = deepcopy(affinity_matrix)\n",
    "\n",
    "    # iterate over each element and compute weighted value\n",
    "    matrix_iterator = range(len(affinity_matrix))\n",
    "    for row in matrix_iterator:\n",
    "        for col in matrix_iterator:\n",
    "            # ignore diagonal\n",
    "            if row == col:\n",
    "                continue\n",
    "\n",
    "            # scale weight to be between -100 to 100\n",
    "            weight = 1.0 + 99.0 * affinity_matrix[row][col]\n",
    "\n",
    "            # Penalize recent pairings by increasing weight of pairs that have NOT occurred recently for last 3 pairings\n",
    "            # ex. If A and B have not paired last time, increase their weight by 80 * 0.5^1\n",
    "            # ex. If they also didn't pair time before, further increase their weight by 80 * 0.5^2 and so on (up to 3)\n",
    "            # only give extra weight if rating is not -1\n",
    "            if affinity_matrix[row][col] != -1:\n",
    "                for index, pairing in enumerate(recent_pairings):\n",
    "                    helper = index_user_mapping[str(row)]\n",
    "                    helpee = index_user_mapping[str(col)]\n",
    "\n",
    "                    # helper-helpee pairing does not exist in the current pairing\n",
    "                    if helper in pairing and pairing[helper] != helpee:\n",
    "                        weight += 80.0 * (0.5 ** (index + 1))\n",
    "\n",
    "            # add some random perturbation, between 0-20, to guarentee strict ordering\n",
    "            weight += random.random() * 20.0\n",
    "\n",
    "            # store new edge weight\n",
    "            directed_graph[row][col] = math.floor(weight)\n",
    "\n",
    "    return directed_graph\n",
    "\n",
    "\n",
    "def create_undirected_graph(affinity_matrix, index_user_mapping, recent_pairings):\n",
    "    \"\"\"\n",
    "    Converts an affinity matrix into a weighted matrix that represented a directed graph.\n",
    "        Weight is calculated based on previous recent pairings and some random perturbation.\n",
    "\n",
    "    Input:\n",
    "        affinity_matrix (list of list of numbers): matrix of affinities. 0 if no affinity between users.\n",
    "        index_user_mapping (dict): dict where keys are numbers and values are userIds mapping matrix index to users.\n",
    "        recent_pairings (list of dict): up to 3 pairing sessions, ordered by recency,\n",
    "            with each dict containing helper-helpee pairs\n",
    "\n",
    "    Output:\n",
    "        (list of list of numbers): weighted matrix\n",
    "    \"\"\"\n",
    "    # dont modify original dataframe\n",
    "    undirected_graph = []\n",
    "\n",
    "    # iterate over each element and compute weighted value\n",
    "    matrix_iterator = range(len(affinity_matrix))\n",
    "    for row in matrix_iterator:\n",
    "        for col in matrix_iterator:\n",
    "            # ignore diagonal and lower triangular portion of matrix\n",
    "            if col <= row:\n",
    "                continue\n",
    "\n",
    "            # ignore edge if either has rated each other a -1\n",
    "            if affinity_matrix[row][col] != -1 and affinity_matrix[col][row] != -1:\n",
    "                # scale weight to be between -100 to 100. average the edges between two users.\n",
    "                weight = (\n",
    "                    1.0\n",
    "                    + 99.0\n",
    "                    * (affinity_matrix[row][col] + affinity_matrix[col][row])\n",
    "                    / 2.0\n",
    "                )\n",
    "\n",
    "                # Penalize recent pairings by increasing weight of pairs that have NOT occurred recently for last 3 pairings\n",
    "                # ex. If A and B have not paired last time, increase their weight by 80 * 0.5^1\n",
    "                # ex. If they also didn't pair time before, further increase their weight by 80 * 0.5^2 and so on (up to 3)\n",
    "                for index, pairing in enumerate(recent_pairings):\n",
    "                    helper = index_user_mapping[str(row)]\n",
    "                    helpee = index_user_mapping[str(col)]\n",
    "\n",
    "                    # helper-helpee pairing does not exist in the current pairing\n",
    "                    if helper in pairing and pairing[helper] != helpee:\n",
    "                        weight += 80.0 * 0.5 ** (index + 1)\n",
    "\n",
    "                # add some random perturbation, between 0-20, to guarentee strict ordering\n",
    "                weight += random.random() * 20\n",
    "\n",
    "                # store new edge weight\n",
    "                undirected_graph.append([row, col, math.floor(weight)])\n",
    "\n",
    "    return undirected_graph\n",
    "\n",
    "\n",
    "def compute_mwm_stability(group_pair_id, user_index_dict, preference_matrix):\n",
    "    \"\"\"\n",
    "    Computes the stability of a previous MWM matching, given a preference_matrix.\n",
    "\n",
    "    Input:\n",
    "        group_pair_id (string): pairing to determine stability for.\n",
    "        user_index_dict (dict): mapping of users to index where indices are 1-indexed strings.\n",
    "        preferences (matrix, list of lists of numbers): n-by-m preference matrix containing preferences for each person.\n",
    "            m = n - 1, so each person has rated all other people.\n",
    "            Each row is a 1-indexed ordered ranking of others in the pool.\n",
    "            Therefore max(preferences[person]) <= number people and min(preferences[person]) = 1.\n",
    "\n",
    "    Output:\n",
    "        (boolean): whether MWM matching was stable. None if cannot determine.\n",
    "    \"\"\"\n",
    "    # create a preference lookup table\n",
    "    # person_number : [list of preferences]\n",
    "    curr_pref_dict = {\n",
    "        str(x + 1): [str(y) for y in preference_matrix[x]]\n",
    "        for x in range(len(preference_matrix))\n",
    "    }\n",
    "\n",
    "    # create a dict of dicts holding index of each person ranked\n",
    "    # person number : {person : rank_index }\n",
    "    curr_ranks = {\n",
    "        index: dict(zip(value, range(len(value))))\n",
    "        for (index, value) in curr_pref_dict.items()\n",
    "    }\n",
    "\n",
    "    # attempt to create pairing dict and determine stability\n",
    "    try:\n",
    "        # create pairing dict\n",
    "        curr_pairings = pairings[pairings[\"group_pairing_id\"] == group_pair_id][\n",
    "            \"pairings\"\n",
    "        ].tolist()[0]\n",
    "        curr_pairing_dict = create_pairing_dict(user_index_dict, curr_pairings)\n",
    "\n",
    "        # determine and return stability\n",
    "        return verify_stability(curr_pairing_dict, curr_ranks)\n",
    "    except KeyError:\n",
    "        # matching could not be computed since some data is missing\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_previous_matching(group_pair_id):\n",
    "    \"\"\"\n",
    "    Fetches and returns a previous matching.\n",
    "\n",
    "    Input:\n",
    "        group_pair_id (string): pairing to fetch\n",
    "        user_index_dict (dict): mapping of users to index where indices are 1-indexed strings.\n",
    "\n",
    "    Output:\n",
    "        (dict): dict containing bi-directional pairings from the pairing list with keys and values being user ids\n",
    "                ex. { 'user-id-a': 'user-id-b', 'user-id-b': 'user-id-a'}\n",
    "    \"\"\"\n",
    "    # get pairings for matching session\n",
    "    curr_pairings = pairings[pairings[\"group_pairing_id\"] == group_pair_id][\n",
    "        \"pairings\"\n",
    "    ].tolist()[0]\n",
    "\n",
    "    # create and return output dict\n",
    "    output_dict = {}\n",
    "    for curr_pairing in curr_pairings:\n",
    "        if \"secondUserId\" in curr_pairing:\n",
    "            output_dict[curr_pairing[\"firstUserId\"]] = curr_pairing[\"secondUserId\"]\n",
    "            output_dict[curr_pairing[\"secondUserId\"]] = curr_pairing[\"firstUserId\"]\n",
    "        else:\n",
    "            output_dict[curr_pairing[\"firstUserId\"]] = \"\"\n",
    "\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "def create_userid_matching_dict(matching, index_user_mapping):\n",
    "    \"\"\"\n",
    "    Converts a index_user_mapping ({'1': '2', '2': '1'}) into a user_id mapping ({'user-id-a': 'user-id-b', 'user-id-b': 'user-id-a'}),\n",
    "        given a matching.\n",
    "\n",
    "    Input:\n",
    "        matching (list): list of indicces\n",
    "        index_user_mapping (dict): dict where keys are numbers and values are userIds mapping matrix index to users.\n",
    "\n",
    "    Output:\n",
    "        (dict): user id matching dict ({'user-id-a': 'user-id-b', 'user-id-b': 'user-id-a'})\n",
    "    \"\"\"\n",
    "    output_dict = {}\n",
    "\n",
    "    for index, value in enumerate(matching):\n",
    "        if value == -1:\n",
    "            output_dict[index_user_mapping[str(index)]] = \"\"\n",
    "        else:\n",
    "            output_dict[index_user_mapping[str(index)]] = index_user_mapping[str(value)]\n",
    "\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "def get_affinities_for_matching(input_affinities, user_id_matching_dict, remap=True):\n",
    "    \"\"\"\n",
    "    Creates a dictionary mapping user id to affinity value under a matching.\n",
    "\n",
    "    Input:\n",
    "        input_affinities (pandas DataFrame): dataframe with helpeeId, helperId, and value columns.\n",
    "        user_id_matching_dict (dict): matching where keys and values are user ids ({'user-id-a': 'user-id-b', 'user-id-b': 'user-id-a'})\n",
    "        remap (boolean): optional whether affinity values should be remapped to interface values.\n",
    "\n",
    "    Output:\n",
    "        (dict): keys are all user id with the affinity they reported for.\n",
    "            ex. {'user-id-a': 1, 'user-id-b': 0.33}\n",
    "    \"\"\"\n",
    "    # dont modify original dataframe\n",
    "    affinities = deepcopy(input_affinities)\n",
    "    affinities.drop_duplicates(keep=\"last\", inplace=True)\n",
    "\n",
    "    # remap data values to UI values\n",
    "    if remap:\n",
    "        value_mappings = {\"-1.0\": 1, \"0.0\": 2, \"0.33\": 3, \"0.66\": 4, \"1.0\": 5}\n",
    "        affinities[\"value\"] = affinities[\"value\"].astype(str)\n",
    "        affinities.replace({\"value\": value_mappings}, inplace=True)\n",
    "\n",
    "    # create output dict\n",
    "    matching_affinity_dict = {}\n",
    "    for helper, match in user_id_matching_dict.items():\n",
    "        # ignore unmatched\n",
    "        if match == \"\":\n",
    "            continue\n",
    "\n",
    "        # get current affinity for helper with a match\n",
    "        curr_affinity = affinities[\n",
    "            (affinities[\"helperId\"] == helper) & (affinities[\"helpeeId\"] == match)\n",
    "        ][\"value\"].tolist()\n",
    "        if len(curr_affinity) > 0:\n",
    "            matching_affinity_dict[helper] = curr_affinity[0]\n",
    "        else:\n",
    "            matching_affinity_dict[helper] = (\n",
    "                0  # TODO: what should you put for no affinity\n",
    "            )\n",
    "\n",
    "    return matching_affinity_dict\n",
    "\n",
    "\n",
    "# def compute_mwm_stability(mwm_matching, preference_matrix):\n",
    "#     \"\"\"\n",
    "#     Computes the stability of a MWM matching, given the matching and a preference_matrix.\n",
    "\n",
    "#     Input:\n",
    "#         mwm_matching (list): list of numbers indicating matching.\n",
    "#         preferences (matrix, list of lists of numbers): n-by-m preference matrix containing preferences for each person.\n",
    "#             m = n - 1, so each person has rated all other people.\n",
    "#             Each row is a 1-indexed ordered ranking of others in the pool.\n",
    "#             Therefore max(preferences[person]) <= number people and min(preferences[person]) = 1.\n",
    "\n",
    "#     Output:\n",
    "#         (boolean): whether MWM matching was stable. None if cannot determine.\n",
    "#     \"\"\"\n",
    "#     # create a preference lookup table\n",
    "#     # person_number : [list of preferences]\n",
    "#     curr_pref_dict = {\n",
    "#         str(x + 1): [str(y) for y in preference_matrix[x]] for x in range(len(preference_matrix))\n",
    "#     }\n",
    "\n",
    "#     # create a dict of dicts holding index of each person ranked\n",
    "#     # person number : {person : rank_index }\n",
    "#     curr_ranks = {index: dict(zip(value, range(len(value)))) for (index, value) in curr_pref_dict.items()}\n",
    "\n",
    "#     # create 1-indexed pairing dict without unmatched pairings\n",
    "#     curr_pairing_dict = {str(index): str(value) for index, value in enumerate(temp_matching) if value != -1}\n",
    "\n",
    "#     # determine and return stability\n",
    "#     try:\n",
    "#         return verify_stability(curr_pairing_dict, curr_ranks)\n",
    "#     except KeyError:\n",
    "#     # stability could not be computed since some data is missing\n",
    "#         return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute matching helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sr_matching_pair_research(\n",
    "    group_pair_id, handle_odd_method=\"remove\", remove_all=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs stable matching on pair research data, given a group_pair_id to run matching for.\n",
    "\n",
    "    Input:\n",
    "        group_pair_id (string): group pairing to run matching on\n",
    "        handle_odd_method (string): handling odd cases by either adding ('add') or removing ('remove') user\n",
    "        remove_all (boolean): whether to try again if randomly removing a person fails\n",
    "\n",
    "    Output:\n",
    "        (dict): output of matching, along with matching metadata\n",
    "    \"\"\"\n",
    "    # create affinity matrix and index-user dict\n",
    "    curr_affinities = deepcopy(\n",
    "        affinities_history[affinities_history[\"group_pairing_id\"] == group_pair_id]\n",
    "    )\n",
    "    curr_tasks = deepcopy(\n",
    "        tasks_history[tasks_history[\"group_pairing_id\"] == group_pair_id]\n",
    "    )\n",
    "    curr_affinity_matrix, curr_index_user_mapping = create_affinity_matrix(\n",
    "        curr_affinities[[\"helperId\", \"helpeeId\", \"value\"]], curr_tasks\n",
    "    )\n",
    "\n",
    "    # transform index-user dict into user-index dict where indices are 1-indexed\n",
    "    curr_user_index_dict = {\n",
    "        str(v): str(int(k) + 1) for (k, v) in curr_index_user_mapping.items()\n",
    "    }\n",
    "\n",
    "    # get recent pairings and create input graphs\n",
    "    curr_recent_pairings = get_recent_pairings(group_pair_id, 3)\n",
    "\n",
    "    curr_directed_graph = create_directed_graph(\n",
    "        curr_affinity_matrix, curr_index_user_mapping, curr_recent_pairings\n",
    "    )\n",
    "    curr_undirected_graph = create_undirected_graph(\n",
    "        curr_affinity_matrix, curr_index_user_mapping, curr_recent_pairings\n",
    "    )\n",
    "\n",
    "    # create current preference matrix given the directed graph\n",
    "    curr_pref_matrix = create_preference_matrix(curr_directed_graph)\n",
    "\n",
    "    # run pair research matching algorithm\n",
    "    matching_output = create_matching_output(\n",
    "        {\n",
    "            \"directed_graph\": curr_directed_graph,\n",
    "            \"undirected_graph\": curr_undirected_graph,\n",
    "        },\n",
    "        handle_odd_method=handle_odd_method,\n",
    "        remove_all=remove_all,\n",
    "        debug=True,\n",
    "    )\n",
    "\n",
    "    # create user id matching dict with affinities\n",
    "    mwm_userid_matching_dict = get_previous_matching(\n",
    "        group_pair_id\n",
    "    )  # TODO: use matching output\n",
    "    mwm_affinities = get_affinities_for_matching(\n",
    "        curr_affinities[[\"helperId\", \"helpeeId\", \"value\"]], mwm_userid_matching_dict\n",
    "    )\n",
    "\n",
    "    sr_userid_matching_dict = create_userid_matching_dict(\n",
    "        matching_output[\"stable_result\"], curr_index_user_mapping\n",
    "    )\n",
    "    sr_mwm_userid_matching_dict = create_userid_matching_dict(\n",
    "        matching_output[\"matching\"], curr_index_user_mapping\n",
    "    )\n",
    "\n",
    "    # create affinity dictionaries\n",
    "    sr_affinities = get_affinities_for_matching(\n",
    "        curr_affinities[[\"helperId\", \"helpeeId\", \"value\"]], sr_userid_matching_dict\n",
    "    )\n",
    "    sr_mwm_affinities = get_affinities_for_matching(\n",
    "        curr_affinities[[\"helperId\", \"helpeeId\", \"value\"]], sr_mwm_userid_matching_dict\n",
    "    )\n",
    "\n",
    "    # determine stability of MWM matching\n",
    "    # TODO: use created MWM matching to determine if stable\n",
    "    mwm_stability = compute_mwm_stability(\n",
    "        group_pair_id, curr_user_index_dict, curr_pref_matrix\n",
    "    )\n",
    "    #     mwm_stability = compute_mwm_stability(matching_output['mwm_result_full'], curr_pref_matrix)\n",
    "\n",
    "    # create metadata about the current affinity and add data to pairing_data\n",
    "    group_id, pairing_id = group_pair_id.split(\"-\")\n",
    "    user_count = len(curr_affinity_matrix)\n",
    "    curr_timestamp = pairs_history[pairs_history.group_pairing_id == group_pair_id].iat[\n",
    "        0, pairs_history.columns.get_loc(\"timestamp\")\n",
    "    ]\n",
    "\n",
    "    mwm_stable_text = \"NA\"\n",
    "    if mwm_stability is not None:\n",
    "        mwm_stable_text = \"stable\" if mwm_stability else \"unstable\"\n",
    "\n",
    "    # create and return matching data\n",
    "    matching_data = {\n",
    "        \"group_pair_id\": group_pair_id,\n",
    "        \"group_id\": group_id,\n",
    "        \"pairing_id\": pairing_id,\n",
    "        \"timestamp\": curr_timestamp,\n",
    "        \"user_count\": user_count,\n",
    "        \"user_parity\": \"even\" if user_count % 2 == 0 else \"odd\",\n",
    "        \"odd_handling\": handle_odd_method,\n",
    "        \"final_matching\": matching_output[\"matching\"],\n",
    "        \"final_affinities\": sr_mwm_affinities,  # TODO\n",
    "        \"sr_result\": matching_output[\"stable_result\"],\n",
    "        \"sr_affinities\": sr_affinities,  # TODO\n",
    "        \"sr_stability\": \"stable\" if matching_output[\"fully_stable\"] else \"unstable\",\n",
    "        \"sr_debug\": matching_output[\"stable_debug\"],\n",
    "        \"sr_cardinality\": compute_matching_cardinality(\n",
    "            matching_output[\"stable_result\"]\n",
    "        ),\n",
    "        \"mwm_result\": matching_output[\"mwm_result_full\"],\n",
    "        \"mwm_affinities\": mwm_affinities,  # TODO\n",
    "        \"mwm_stability\": mwm_stable_text,\n",
    "        \"affinity_matrix\": curr_affinity_matrix,\n",
    "        \"directed_graph\": curr_directed_graph,\n",
    "        \"undirected_graph\": curr_undirected_graph,\n",
    "        \"preference_matrix\": curr_pref_matrix,\n",
    "        \"index_user_mapping\": curr_index_user_mapping,\n",
    "    }\n",
    "    return matching_data\n",
    "\n",
    "\n",
    "def sr_matching_pair_research_wrapper(exec_dicts):\n",
    "    \"\"\"\n",
    "    Wrapper for sr_matching_pair_research that allows for changing optional parameters.\n",
    "\n",
    "    Input:\n",
    "        exec_dicts (list of dicts): contains group_pair_id, handle_odd_method, and remove_all\n",
    "\n",
    "    Output:\n",
    "        (dict): output of matching, along with matching metadata\n",
    "    \"\"\"\n",
    "    return sr_matching_pair_research(\n",
    "        exec_dicts[\"group_pair_id\"],\n",
    "        exec_dicts[\"handle_odd_method\"],\n",
    "        exec_dicts[\"remove_all\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def execute_sr_matching(\n",
    "    group_pairing_ids, handle_odd_method=\"remove\", remove_all=True, parallel=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Wrapper for computing pair research matchings that calls sr_matching_pair_research_wrapper.\n",
    "\n",
    "    Input:\n",
    "        group_pairing_ids (list of string): unique group pairing ids to conduct matching on.\n",
    "        remove_all (boolean): whether to try again if randomly removing a person fails\n",
    "        parallel (boolean): run matching in parallel across all group_pairing_ids\n",
    "\n",
    "    Output:\n",
    "        (DataFrame): matchings computed for pair research data\n",
    "    \"\"\"\n",
    "    pairing_data = []\n",
    "    exec_dicts = [\n",
    "        {\n",
    "            \"group_pair_id\": group_pair_id,\n",
    "            \"handle_odd_method\": handle_odd_method,\n",
    "            \"remove_all\": remove_all,\n",
    "        }\n",
    "        for group_pair_id in group_pairing_ids\n",
    "    ]\n",
    "\n",
    "    # compute pairings\n",
    "    if parallel:\n",
    "        pool = mp.Pool(processes=mp.cpu_count())\n",
    "        pairing_data = pool.map(sr_matching_pair_research_wrapper, exec_dicts)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    else:\n",
    "        pairing_data = []\n",
    "        for exec_dict in tqdm(exec_dicts):\n",
    "            pairing_data.append(sr_matching_pair_research_wrapper(exec_dict))\n",
    "        # pairing_data = [sr_matching_pair_research_wrapper(exec_dict) for exec_dict in exec_dicts]\n",
    "\n",
    "    return pd.DataFrame(pairing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove One User Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a6e40113594f8cab04593c693b7f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined matching not valid. [2, 4, 0, -1, 1, -1, 7, 6, -1]\n",
      "Combined matching not valid. [8, -1, 7, 4, 3, 9, -1, 2, 0, 5]\n",
      "Combined matching not valid. [1, 0, 7, 5, -1, 3, -1, 2]\n",
      "Combined matching not valid. [4, 9, -1, 11, 0, 6, 5, 10, -1, 1, 7, 3]\n",
      "Combined matching not valid. [5, 3, -1, 1, -1, 0]\n",
      "Combined matching not valid. [6, 4, 9, -1, 1, 10, 0, -1, -1, 2, 5]\n",
      "Combined matching not valid. [-1, -1, 6, 4, 3, 9, 2, 8, 7, 5]\n",
      "Combined matching not valid. [7, 3, 4, 1, 2, -1, -1, 0]\n",
      "Combined matching not valid. [2, -1, 0, 8, 6, -1, 4, 9, 3, 7]\n",
      "Combined matching not valid. [2, 4, 0, 6, 1, -1, 3, -1]\n",
      "Combined matching not valid. [7, -1, 5, 6, -1, 2, 3, 0]\n",
      "Combined matching not valid. [8, 2, 1, 6, 7, 10, 3, 4, 0, -1, 5, 12, 11, -1]\n",
      "Combined matching not valid. [7, 2, 1, 6, 10, -1, 3, 0, 13, -1, 4, 12, 11, 8]\n",
      "Combined matching not valid. [1, 0, 9, 11, 6, 17, 4, 8, 7, 2, 12, 3, 10, -1, -1, 16, 15, 5]\n",
      "Combined matching not valid. [16, 15, 9, 6, 5, 4, 3, 12, 13, 2, -1, 17, 7, 8, -1, 1, 0, 11]\n",
      "Combined matching not valid. [2, -1, 0, -1]\n",
      "Combined matching not valid. [7, 9, -1, 11, 5, 4, -1, 0, 13, 1, 12, 3, 10, 8]\n",
      "Combined matching not valid. [5, 3, 7, 1, -1, 0, -1, 2, 10, 11, 8, 9]\n",
      "Combined matching not valid. [-1, 11, -1, 8, 10, 7, 9, 5, 3, 6, 4, 1]\n",
      "Combined matching not valid. [10, 11, 12, 4, 3, 6, 5, -1, 9, 8, 0, 1, 2, -1]\n",
      "Combined matching not valid. [2, -1, 0, 7, 10, 11, -1, 3, 9, 8, 4, 5]\n",
      "Combined matching not valid. [3, 5, 10, 0, -1, 1, 8, -1, 6, 11, 2, 9, -1]\n",
      "Stable Roommates Matching Results\n",
      "Stable: 841 (81.73%)\n",
      "Unstable: 188 (18.27%)\n",
      "Total: 1029 (100.00%)\n",
      "\n",
      "\n",
      "Maximum Weighted Matching Results\n",
      "Stable: 343 (33.33%)\n",
      "Unstable: 671 (65.21%)\n",
      "NA (could not determine stability): 15 (1.46%)\n",
      "Total: 1029 (100.00%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_pair_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>pairing_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_count</th>\n",
       "      <th>user_parity</th>\n",
       "      <th>odd_handling</th>\n",
       "      <th>final_matching</th>\n",
       "      <th>final_affinities</th>\n",
       "      <th>sr_result</th>\n",
       "      <th>...</th>\n",
       "      <th>sr_debug</th>\n",
       "      <th>sr_cardinality</th>\n",
       "      <th>mwm_result</th>\n",
       "      <th>mwm_affinities</th>\n",
       "      <th>mwm_stability</th>\n",
       "      <th>affinity_matrix</th>\n",
       "      <th>directed_graph</th>\n",
       "      <th>undirected_graph</th>\n",
       "      <th>preference_matrix</th>\n",
       "      <th>index_user_mapping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27syMcotb279YaP2u-3G6iXFybGhQdsjDct</td>\n",
       "      <td>27syMcotb279YaP2u</td>\n",
       "      <td>3G6iXFybGhQdsjDct</td>\n",
       "      <td>2023-04-13 08:43:23.516</td>\n",
       "      <td>7</td>\n",
       "      <td>odd</td>\n",
       "      <td>remove</td>\n",
       "      <td>[6, -1, 4, 5, 2, 3, 0]</td>\n",
       "      <td>{'TFpfXZLxwfzEorfGD': 0, '7Bu7DRa9Js5B2SkP2': ...</td>\n",
       "      <td>[6, -1, 4, 5, 2, 3, 0]</td>\n",
       "      <td>...</td>\n",
       "      <td>Stable matching found after Phase 1.</td>\n",
       "      <td>6</td>\n",
       "      <td>[6, 2, 1, -1, 5, 4, 0]</td>\n",
       "      <td>{'66PYzPiXdpro84gaR': 0, 'TFpfXZLxwfzEorfGD': ...</td>\n",
       "      <td>stable</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[[0, 65, 42, 63, 79, 72, 86], [64, 0, 82, 89, ...</td>\n",
       "      <td>[[0, 1, 79], [0, 2, 32], [0, 3, 59], [0, 5, 13...</td>\n",
       "      <td>[[7, 5, 6, 2, 4, 3], [4, 3, 6, 1, 5, 7], [2, 6...</td>\n",
       "      <td>{'0': 'TFpfXZLxwfzEorfGD', '1': 'SKMaq7QzxYcNd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27syMcotb279YaP2u-44wNFcfPQZ9PJGKFA</td>\n",
       "      <td>27syMcotb279YaP2u</td>\n",
       "      <td>44wNFcfPQZ9PJGKFA</td>\n",
       "      <td>2023-05-02 01:52:25.623</td>\n",
       "      <td>10</td>\n",
       "      <td>even</td>\n",
       "      <td>remove</td>\n",
       "      <td>[3, 7, 6, 0, 5, 4, 2, 1, 9, 8]</td>\n",
       "      <td>{'TFpfXZLxwfzEorfGD': 1, '66PYzPiXdpro84gaR': ...</td>\n",
       "      <td>[3, 7, 6, 0, 5, 4, 2, 1, 9, 8]</td>\n",
       "      <td>...</td>\n",
       "      <td>Stable matching found after Phase 1.</td>\n",
       "      <td>10</td>\n",
       "      <td>[4, 7, 6, 5, 0, 3, 2, 1, 9, 8]</td>\n",
       "      <td>{'sanGBbAp7tXpTMfHN': 3, '7Bu7DRa9Js5B2SkP2': ...</td>\n",
       "      <td>unstable</td>\n",
       "      <td>[[0, -1.0, -1.0, -1.0, 0, 0.66, -1.0, -1.0, -1...</td>\n",
       "      <td>[[0, -96, -96, -84, 61, 108, -98, -97, -94, -8...</td>\n",
       "      <td>[[0, 4, 62], [0, 5, 71], [1, 2, 82], [1, 3, 93...</td>\n",
       "      <td>[[6, 5, 4, 10, 9, 2, 3, 8, 7], [8, 9, 3, 1, 5,...</td>\n",
       "      <td>{'0': 'TFpfXZLxwfzEorfGD', '1': '66PYzPiXdpro8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27syMcotb279YaP2u-A9peJrKgSA7qng696</td>\n",
       "      <td>27syMcotb279YaP2u</td>\n",
       "      <td>A9peJrKgSA7qng696</td>\n",
       "      <td>2023-04-24 03:47:02.227</td>\n",
       "      <td>10</td>\n",
       "      <td>even</td>\n",
       "      <td>remove</td>\n",
       "      <td>[7, 9, 6, 5, 8, 3, 2, 0, 4, 1]</td>\n",
       "      <td>{'TFpfXZLxwfzEorfGD': 1, '66PYzPiXdpro84gaR': ...</td>\n",
       "      <td>[7, 9, 6, 5, 8, 3, 2, 0, 4, 1]</td>\n",
       "      <td>...</td>\n",
       "      <td>Stable matching found after Phase 1.</td>\n",
       "      <td>10</td>\n",
       "      <td>[3, 9, 6, 0, 5, 4, 2, 8, 7, 1]</td>\n",
       "      <td>{'MP8Rx75gtnRvDZgFk': 0, 'wkEeKMNEDceiNrmnZ': ...</td>\n",
       "      <td>unstable</td>\n",
       "      <td>[[0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, ...</td>\n",
       "      <td>[[0, -87, -98, 62, -94, -86, -87, -84, -84, -9...</td>\n",
       "      <td>[[0, 3, 115], [1, 2, 82], [1, 3, 89], [1, 4, 7...</td>\n",
       "      <td>[[4, 8, 9, 6, 2, 7, 10, 5, 3], [4, 10, 1, 7, 3...</td>\n",
       "      <td>{'0': 'TFpfXZLxwfzEorfGD', '1': '66PYzPiXdpro8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27syMcotb279YaP2u-GALL37sjanTe42yDq</td>\n",
       "      <td>27syMcotb279YaP2u</td>\n",
       "      <td>GALL37sjanTe42yDq</td>\n",
       "      <td>2023-04-13 08:42:46.621</td>\n",
       "      <td>7</td>\n",
       "      <td>odd</td>\n",
       "      <td>remove</td>\n",
       "      <td>[5, -1, 6, 4, 3, 0, 2]</td>\n",
       "      <td>{'TFpfXZLxwfzEorfGD': 0, '7Bu7DRa9Js5B2SkP2': ...</td>\n",
       "      <td>[5, -1, 6, 4, 3, 0, 2]</td>\n",
       "      <td>...</td>\n",
       "      <td>Stable matching found after Phase 1.</td>\n",
       "      <td>6</td>\n",
       "      <td>[5, 3, 6, 1, -1, 0, 2]</td>\n",
       "      <td>{'sanGBbAp7tXpTMfHN': 5, 'SKMaq7QzxYcNddSoT': ...</td>\n",
       "      <td>unstable</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[[0, 42, 71, 62, 75, 83, 62], [45, 0, 65, 79, ...</td>\n",
       "      <td>[[0, 1, 34], [0, 2, 78], [0, 3, 74], [0, 5, 13...</td>\n",
       "      <td>[[6, 5, 3, 4, 7, 2], [4, 5, 7, 6, 3, 1], [2, 1...</td>\n",
       "      <td>{'0': 'TFpfXZLxwfzEorfGD', '1': 'SKMaq7QzxYcNd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27syMcotb279YaP2u-KQeEk3nih5NnRFRvn</td>\n",
       "      <td>27syMcotb279YaP2u</td>\n",
       "      <td>KQeEk3nih5NnRFRvn</td>\n",
       "      <td>2023-04-23 15:44:15.341</td>\n",
       "      <td>8</td>\n",
       "      <td>even</td>\n",
       "      <td>remove</td>\n",
       "      <td>[6, 2, 1, 7, 5, 4, 0, 3]</td>\n",
       "      <td>{'TFpfXZLxwfzEorfGD': 0, 'SKMaq7QzxYcNddSoT': ...</td>\n",
       "      <td>[6, 2, 1, 7, 5, 4, 0, 3]</td>\n",
       "      <td>...</td>\n",
       "      <td>Stable matching found after Phase 2.</td>\n",
       "      <td>8</td>\n",
       "      <td>[6, 7, 3, 2, 5, 4, 0, 1]</td>\n",
       "      <td>{'2y7tESxwQFwro8Jca': 4, 'sanGBbAp7tXpTMfHN': ...</td>\n",
       "      <td>unstable</td>\n",
       "      <td>[[0, 0, 0, -1.0, -1.0, 0, 0, -1.0], [0, 0, 0, ...</td>\n",
       "      <td>[[0, 53, 53, -84, -88, 22, 51, -97], [75, 0, 8...</td>\n",
       "      <td>[[0, 1, 56], [0, 2, 119], [0, 5, 74], [0, 6, 8...</td>\n",
       "      <td>[[2, 3, 7, 6, 4, 5, 8], [8, 6, 3, 4, 7, 1, 5],...</td>\n",
       "      <td>{'0': 'TFpfXZLxwfzEorfGD', '1': 'SKMaq7QzxYcNd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         group_pair_id           group_id         pairing_id  \\\n",
       "0  27syMcotb279YaP2u-3G6iXFybGhQdsjDct  27syMcotb279YaP2u  3G6iXFybGhQdsjDct   \n",
       "1  27syMcotb279YaP2u-44wNFcfPQZ9PJGKFA  27syMcotb279YaP2u  44wNFcfPQZ9PJGKFA   \n",
       "2  27syMcotb279YaP2u-A9peJrKgSA7qng696  27syMcotb279YaP2u  A9peJrKgSA7qng696   \n",
       "3  27syMcotb279YaP2u-GALL37sjanTe42yDq  27syMcotb279YaP2u  GALL37sjanTe42yDq   \n",
       "4  27syMcotb279YaP2u-KQeEk3nih5NnRFRvn  27syMcotb279YaP2u  KQeEk3nih5NnRFRvn   \n",
       "\n",
       "                timestamp  user_count user_parity odd_handling  \\\n",
       "0 2023-04-13 08:43:23.516           7         odd       remove   \n",
       "1 2023-05-02 01:52:25.623          10        even       remove   \n",
       "2 2023-04-24 03:47:02.227          10        even       remove   \n",
       "3 2023-04-13 08:42:46.621           7         odd       remove   \n",
       "4 2023-04-23 15:44:15.341           8        even       remove   \n",
       "\n",
       "                   final_matching  \\\n",
       "0          [6, -1, 4, 5, 2, 3, 0]   \n",
       "1  [3, 7, 6, 0, 5, 4, 2, 1, 9, 8]   \n",
       "2  [7, 9, 6, 5, 8, 3, 2, 0, 4, 1]   \n",
       "3          [5, -1, 6, 4, 3, 0, 2]   \n",
       "4        [6, 2, 1, 7, 5, 4, 0, 3]   \n",
       "\n",
       "                                    final_affinities  \\\n",
       "0  {'TFpfXZLxwfzEorfGD': 0, '7Bu7DRa9Js5B2SkP2': ...   \n",
       "1  {'TFpfXZLxwfzEorfGD': 1, '66PYzPiXdpro84gaR': ...   \n",
       "2  {'TFpfXZLxwfzEorfGD': 1, '66PYzPiXdpro84gaR': ...   \n",
       "3  {'TFpfXZLxwfzEorfGD': 0, '7Bu7DRa9Js5B2SkP2': ...   \n",
       "4  {'TFpfXZLxwfzEorfGD': 0, 'SKMaq7QzxYcNddSoT': ...   \n",
       "\n",
       "                        sr_result  ...                              sr_debug  \\\n",
       "0          [6, -1, 4, 5, 2, 3, 0]  ...  Stable matching found after Phase 1.   \n",
       "1  [3, 7, 6, 0, 5, 4, 2, 1, 9, 8]  ...  Stable matching found after Phase 1.   \n",
       "2  [7, 9, 6, 5, 8, 3, 2, 0, 4, 1]  ...  Stable matching found after Phase 1.   \n",
       "3          [5, -1, 6, 4, 3, 0, 2]  ...  Stable matching found after Phase 1.   \n",
       "4        [6, 2, 1, 7, 5, 4, 0, 3]  ...  Stable matching found after Phase 2.   \n",
       "\n",
       "  sr_cardinality                      mwm_result  \\\n",
       "0              6          [6, 2, 1, -1, 5, 4, 0]   \n",
       "1             10  [4, 7, 6, 5, 0, 3, 2, 1, 9, 8]   \n",
       "2             10  [3, 9, 6, 0, 5, 4, 2, 8, 7, 1]   \n",
       "3              6          [5, 3, 6, 1, -1, 0, 2]   \n",
       "4              8        [6, 7, 3, 2, 5, 4, 0, 1]   \n",
       "\n",
       "                                      mwm_affinities mwm_stability  \\\n",
       "0  {'66PYzPiXdpro84gaR': 0, 'TFpfXZLxwfzEorfGD': ...        stable   \n",
       "1  {'sanGBbAp7tXpTMfHN': 3, '7Bu7DRa9Js5B2SkP2': ...      unstable   \n",
       "2  {'MP8Rx75gtnRvDZgFk': 0, 'wkEeKMNEDceiNrmnZ': ...      unstable   \n",
       "3  {'sanGBbAp7tXpTMfHN': 5, 'SKMaq7QzxYcNddSoT': ...      unstable   \n",
       "4  {'2y7tESxwQFwro8Jca': 4, 'sanGBbAp7tXpTMfHN': ...      unstable   \n",
       "\n",
       "                                     affinity_matrix  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "1  [[0, -1.0, -1.0, -1.0, 0, 0.66, -1.0, -1.0, -1...   \n",
       "2  [[0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, ...   \n",
       "3  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "4  [[0, 0, 0, -1.0, -1.0, 0, 0, -1.0], [0, 0, 0, ...   \n",
       "\n",
       "                                      directed_graph  \\\n",
       "0  [[0, 65, 42, 63, 79, 72, 86], [64, 0, 82, 89, ...   \n",
       "1  [[0, -96, -96, -84, 61, 108, -98, -97, -94, -8...   \n",
       "2  [[0, -87, -98, 62, -94, -86, -87, -84, -84, -9...   \n",
       "3  [[0, 42, 71, 62, 75, 83, 62], [45, 0, 65, 79, ...   \n",
       "4  [[0, 53, 53, -84, -88, 22, 51, -97], [75, 0, 8...   \n",
       "\n",
       "                                    undirected_graph  \\\n",
       "0  [[0, 1, 79], [0, 2, 32], [0, 3, 59], [0, 5, 13...   \n",
       "1  [[0, 4, 62], [0, 5, 71], [1, 2, 82], [1, 3, 93...   \n",
       "2  [[0, 3, 115], [1, 2, 82], [1, 3, 89], [1, 4, 7...   \n",
       "3  [[0, 1, 34], [0, 2, 78], [0, 3, 74], [0, 5, 13...   \n",
       "4  [[0, 1, 56], [0, 2, 119], [0, 5, 74], [0, 6, 8...   \n",
       "\n",
       "                                   preference_matrix  \\\n",
       "0  [[7, 5, 6, 2, 4, 3], [4, 3, 6, 1, 5, 7], [2, 6...   \n",
       "1  [[6, 5, 4, 10, 9, 2, 3, 8, 7], [8, 9, 3, 1, 5,...   \n",
       "2  [[4, 8, 9, 6, 2, 7, 10, 5, 3], [4, 10, 1, 7, 3...   \n",
       "3  [[6, 5, 3, 4, 7, 2], [4, 5, 7, 6, 3, 1], [2, 1...   \n",
       "4  [[2, 3, 7, 6, 4, 5, 8], [8, 6, 3, 4, 7, 1, 5],...   \n",
       "\n",
       "                                  index_user_mapping  \n",
       "0  {'0': 'TFpfXZLxwfzEorfGD', '1': 'SKMaq7QzxYcNd...  \n",
       "1  {'0': 'TFpfXZLxwfzEorfGD', '1': '66PYzPiXdpro8...  \n",
       "2  {'0': 'TFpfXZLxwfzEorfGD', '1': '66PYzPiXdpro8...  \n",
       "3  {'0': 'TFpfXZLxwfzEorfGD', '1': 'SKMaq7QzxYcNd...  \n",
       "4  {'0': 'TFpfXZLxwfzEorfGD', '1': 'SKMaq7QzxYcNd...  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all pairing instances\n",
    "group_pairing_ids = affinities_history.group_pairing_id.unique()\n",
    "\n",
    "# compute pairings and create DataFrame of results\n",
    "remove_one_pairings_df = execute_sr_matching(\n",
    "    group_pairing_ids, handle_odd_method=\"remove\", remove_all=False, parallel=False\n",
    ")\n",
    "\n",
    "# print stable matching results\n",
    "sr_stable_count = len(\n",
    "    remove_one_pairings_df[remove_one_pairings_df[\"sr_stability\"] == \"stable\"]\n",
    ")\n",
    "sr_unstable_count = len(\n",
    "    remove_one_pairings_df[remove_one_pairings_df[\"sr_stability\"] == \"unstable\"]\n",
    ")\n",
    "sr_total = sr_stable_count + sr_unstable_count\n",
    "\n",
    "output_string = \"Stable Roommates Matching Results\\nStable: {} ({:1.2f}%)\\nUnstable: {} ({:1.2f}%)\\nTotal: {} (100.00%)\\n\\n\"\n",
    "print(\n",
    "    output_string.format(\n",
    "        sr_stable_count,\n",
    "        100 * sr_stable_count / sr_total,\n",
    "        sr_unstable_count,\n",
    "        100 * sr_unstable_count / sr_total,\n",
    "        sr_total,\n",
    "    )\n",
    ")\n",
    "\n",
    "# print mwm results\n",
    "mwm_stable_count = len(\n",
    "    remove_one_pairings_df[remove_one_pairings_df[\"mwm_stability\"] == \"stable\"]\n",
    ")\n",
    "mwm_unstable_count = len(\n",
    "    remove_one_pairings_df[remove_one_pairings_df[\"mwm_stability\"] == \"unstable\"]\n",
    ")\n",
    "mwm_none_count = len(\n",
    "    remove_one_pairings_df[remove_one_pairings_df[\"mwm_stability\"] == \"NA\"]\n",
    ")\n",
    "mwm_total = mwm_stable_count + mwm_unstable_count + mwm_none_count\n",
    "\n",
    "output_string = \"Maximum Weighted Matching Results\\nStable: {} ({:1.2f}%)\\nUnstable: {} ({:1.2f}%)\\nNA (could not determine stability): {} ({:1.2f}%)\\nTotal: {} (100.00%)\"\n",
    "print(\n",
    "    output_string.format(\n",
    "        mwm_stable_count,\n",
    "        100 * mwm_stable_count / mwm_total,\n",
    "        mwm_unstable_count,\n",
    "        100 * mwm_unstable_count / mwm_total,\n",
    "        mwm_none_count,\n",
    "        100 * mwm_none_count / mwm_total,\n",
    "        mwm_total,\n",
    "    )\n",
    ")\n",
    "remove_one_pairings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove another user (and attempt for all users) if Stable Matching isn't Found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8720656bf9f240379c916cb4607e949e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined matching not valid. [8, -1, 7, 4, 3, 9, -1, 2, 0, 5]\n",
      "Combined matching not valid. [1, 0, 7, 5, -1, 3, -1, 2]\n",
      "Combined matching not valid. [4, 9, -1, 11, 0, 6, 5, 10, -1, 1, 7, 3]\n",
      "Combined matching not valid. [5, 3, -1, 1, -1, 0]\n",
      "Combined matching not valid. [-1, -1, 6, 4, 3, 9, 2, 8, 7, 5]\n",
      "Combined matching not valid. [7, 3, 4, 1, 2, -1, -1, 0]\n",
      "Combined matching not valid. [2, -1, 0, 8, 6, -1, 4, 9, 3, 7]\n",
      "Combined matching not valid. [2, 4, 0, 6, 1, -1, 3, -1]\n",
      "Combined matching not valid. [7, -1, 5, 6, -1, 2, 3, 0]\n",
      "Combined matching not valid. [8, 2, 1, 6, 7, 10, 3, 4, 0, -1, 5, 12, 11, -1]\n",
      "Combined matching not valid. [7, 2, 1, 6, 10, -1, 3, 0, 13, -1, 4, 12, 11, 8]\n",
      "Combined matching not valid. [1, 0, 9, 11, 6, 17, 4, 8, 7, 2, 12, 3, 10, -1, -1, 16, 15, 5]\n",
      "Combined matching not valid. [16, 15, 9, 6, 5, 4, 3, 12, 13, 2, -1, 17, 7, 8, -1, 1, 0, 11]\n",
      "Combined matching not valid. [2, -1, 0, -1]\n",
      "Combined matching not valid. [7, 9, -1, 11, 5, 4, -1, 0, 13, 1, 12, 3, 10, 8]\n",
      "Combined matching not valid. [5, 3, 7, 1, -1, 0, -1, 2, 10, 11, 8, 9]\n",
      "Combined matching not valid. [-1, 11, -1, 8, 10, 7, 9, 5, 3, 6, 4, 1]\n",
      "Combined matching not valid. [10, 11, 12, 4, 3, 6, 5, -1, 9, 8, 0, 1, 2, -1]\n",
      "Combined matching not valid. [2, -1, 0, 7, 10, 11, -1, 3, 9, 8, 4, 5]\n",
      "Stable Roommates Matching Results\n",
      "Stable: 926 (89.99%)\n",
      "Unstable: 103 (10.01%)\n",
      "Total: 1029 (100.00%)\n",
      "\n",
      "\n",
      "Maximum Weighted Matching Results\n",
      "Stable: 342 (33.24%)\n",
      "Unstable: 672 (65.31%)\n",
      "NA (could not determine stability): 15 (1.46%)\n",
      "Total: 1029 (100.00%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_pair_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>pairing_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_count</th>\n",
       "      <th>user_parity</th>\n",
       "      <th>odd_handling</th>\n",
       "      <th>final_matching</th>\n",
       "      <th>final_affinities</th>\n",
       "      <th>sr_result</th>\n",
       "      <th>...</th>\n",
       "      <th>sr_debug</th>\n",
       "      <th>sr_cardinality</th>\n",
       "      <th>mwm_result</th>\n",
       "      <th>mwm_affinities</th>\n",
       "      <th>mwm_stability</th>\n",
       "      <th>affinity_matrix</th>\n",
       "      <th>directed_graph</th>\n",
       "      <th>undirected_graph</th>\n",
       "      <th>preference_matrix</th>\n",
       "      <th>index_user_mapping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27syMcotb279YaP2u-3G6iXFybGhQdsjDct</td>\n",
       "      <td>27syMcotb279YaP2u</td>\n",
       "      <td>3G6iXFybGhQdsjDct</td>\n",
       "      <td>2023-04-13 08:43:23.516</td>\n",
       "      <td>7</td>\n",
       "      <td>odd</td>\n",
       "      <td>remove</td>\n",
       "      <td>[2, 5, 0, -1, 6, 1, 4]</td>\n",
       "      <td>{'TFpfXZLxwfzEorfGD': 0, 'SKMaq7QzxYcNddSoT': ...</td>\n",
       "      <td>[2, 5, 0, -1, 6, 1, 4]</td>\n",
       "      <td>...</td>\n",
       "      <td>Stable matching found after Phase 1.</td>\n",
       "      <td>6</td>\n",
       "      <td>[6, 3, -1, 1, 5, 4, 0]</td>\n",
       "      <td>{'66PYzPiXdpro84gaR': 0, 'TFpfXZLxwfzEorfGD': ...</td>\n",
       "      <td>unstable</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[[0, 65, 33, 53, 85, 81, 82], [61, 0, 72, 75, ...</td>\n",
       "      <td>[[0, 1, 78], [0, 2, 48], [0, 3, 58], [0, 5, 12...</td>\n",
       "      <td>[[5, 7, 6, 2, 4, 3], [6, 4, 3, 5, 1, 7], [2, 6...</td>\n",
       "      <td>{'0': 'TFpfXZLxwfzEorfGD', '1': 'SKMaq7QzxYcNd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27syMcotb279YaP2u-44wNFcfPQZ9PJGKFA</td>\n",
       "      <td>27syMcotb279YaP2u</td>\n",
       "      <td>44wNFcfPQZ9PJGKFA</td>\n",
       "      <td>2023-05-02 01:52:25.623</td>\n",
       "      <td>10</td>\n",
       "      <td>even</td>\n",
       "      <td>remove</td>\n",
       "      <td>[3, 7, 6, 0, 5, 4, 2, 1, 9, 8]</td>\n",
       "      <td>{'TFpfXZLxwfzEorfGD': 1, '66PYzPiXdpro84gaR': ...</td>\n",
       "      <td>[3, 7, 6, 0, 5, 4, 2, 1, 9, 8]</td>\n",
       "      <td>...</td>\n",
       "      <td>Stable matching found after Phase 1.</td>\n",
       "      <td>10</td>\n",
       "      <td>[4, 7, 6, 5, 0, 3, 2, 1, 9, 8]</td>\n",
       "      <td>{'sanGBbAp7tXpTMfHN': 3, '7Bu7DRa9Js5B2SkP2': ...</td>\n",
       "      <td>unstable</td>\n",
       "      <td>[[0, -1.0, -1.0, -1.0, 0, 0.66, -1.0, -1.0, -1...</td>\n",
       "      <td>[[0, -96, -96, -84, 61, 108, -98, -97, -94, -8...</td>\n",
       "      <td>[[0, 4, 62], [0, 5, 71], [1, 2, 82], [1, 3, 93...</td>\n",
       "      <td>[[6, 5, 4, 10, 9, 2, 3, 8, 7], [8, 9, 3, 1, 5,...</td>\n",
       "      <td>{'0': 'TFpfXZLxwfzEorfGD', '1': '66PYzPiXdpro8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27syMcotb279YaP2u-A9peJrKgSA7qng696</td>\n",
       "      <td>27syMcotb279YaP2u</td>\n",
       "      <td>A9peJrKgSA7qng696</td>\n",
       "      <td>2023-04-24 03:47:02.227</td>\n",
       "      <td>10</td>\n",
       "      <td>even</td>\n",
       "      <td>remove</td>\n",
       "      <td>[7, 9, 6, 5, 8, 3, 2, 0, 4, 1]</td>\n",
       "      <td>{'TFpfXZLxwfzEorfGD': 1, '66PYzPiXdpro84gaR': ...</td>\n",
       "      <td>[7, 9, 6, 5, 8, 3, 2, 0, 4, 1]</td>\n",
       "      <td>...</td>\n",
       "      <td>Stable matching found after Phase 1.</td>\n",
       "      <td>10</td>\n",
       "      <td>[3, 9, 6, 0, 5, 4, 2, 8, 7, 1]</td>\n",
       "      <td>{'MP8Rx75gtnRvDZgFk': 0, 'wkEeKMNEDceiNrmnZ': ...</td>\n",
       "      <td>unstable</td>\n",
       "      <td>[[0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, ...</td>\n",
       "      <td>[[0, -87, -98, 62, -94, -86, -87, -84, -84, -9...</td>\n",
       "      <td>[[0, 3, 115], [1, 2, 82], [1, 3, 89], [1, 4, 7...</td>\n",
       "      <td>[[4, 8, 9, 6, 2, 7, 10, 5, 3], [4, 10, 1, 7, 3...</td>\n",
       "      <td>{'0': 'TFpfXZLxwfzEorfGD', '1': '66PYzPiXdpro8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27syMcotb279YaP2u-GALL37sjanTe42yDq</td>\n",
       "      <td>27syMcotb279YaP2u</td>\n",
       "      <td>GALL37sjanTe42yDq</td>\n",
       "      <td>2023-04-13 08:42:46.621</td>\n",
       "      <td>7</td>\n",
       "      <td>odd</td>\n",
       "      <td>remove</td>\n",
       "      <td>[5, -1, 6, 4, 3, 0, 2]</td>\n",
       "      <td>{'TFpfXZLxwfzEorfGD': 0, '7Bu7DRa9Js5B2SkP2': ...</td>\n",
       "      <td>[5, -1, 6, 4, 3, 0, 2]</td>\n",
       "      <td>...</td>\n",
       "      <td>Stable matching found after Phase 1.</td>\n",
       "      <td>6</td>\n",
       "      <td>[5, 3, 6, 1, -1, 0, 2]</td>\n",
       "      <td>{'sanGBbAp7tXpTMfHN': 5, 'SKMaq7QzxYcNddSoT': ...</td>\n",
       "      <td>unstable</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[[0, 42, 71, 62, 75, 83, 62], [45, 0, 65, 79, ...</td>\n",
       "      <td>[[0, 1, 34], [0, 2, 78], [0, 3, 74], [0, 5, 13...</td>\n",
       "      <td>[[6, 5, 3, 4, 7, 2], [4, 5, 7, 6, 3, 1], [2, 1...</td>\n",
       "      <td>{'0': 'TFpfXZLxwfzEorfGD', '1': 'SKMaq7QzxYcNd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27syMcotb279YaP2u-KQeEk3nih5NnRFRvn</td>\n",
       "      <td>27syMcotb279YaP2u</td>\n",
       "      <td>KQeEk3nih5NnRFRvn</td>\n",
       "      <td>2023-04-23 15:44:15.341</td>\n",
       "      <td>8</td>\n",
       "      <td>even</td>\n",
       "      <td>remove</td>\n",
       "      <td>[6, 2, 1, 7, 5, 4, 0, 3]</td>\n",
       "      <td>{'TFpfXZLxwfzEorfGD': 0, 'SKMaq7QzxYcNddSoT': ...</td>\n",
       "      <td>[6, 2, 1, 7, 5, 4, 0, 3]</td>\n",
       "      <td>...</td>\n",
       "      <td>Stable matching found after Phase 2.</td>\n",
       "      <td>8</td>\n",
       "      <td>[6, 7, 3, 2, 5, 4, 0, 1]</td>\n",
       "      <td>{'2y7tESxwQFwro8Jca': 4, 'sanGBbAp7tXpTMfHN': ...</td>\n",
       "      <td>unstable</td>\n",
       "      <td>[[0, 0, 0, -1.0, -1.0, 0, 0, -1.0], [0, 0, 0, ...</td>\n",
       "      <td>[[0, 53, 53, -84, -88, 22, 51, -97], [75, 0, 8...</td>\n",
       "      <td>[[0, 1, 56], [0, 2, 119], [0, 5, 74], [0, 6, 8...</td>\n",
       "      <td>[[2, 3, 7, 6, 4, 5, 8], [8, 6, 3, 4, 7, 1, 5],...</td>\n",
       "      <td>{'0': 'TFpfXZLxwfzEorfGD', '1': 'SKMaq7QzxYcNd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         group_pair_id           group_id         pairing_id  \\\n",
       "0  27syMcotb279YaP2u-3G6iXFybGhQdsjDct  27syMcotb279YaP2u  3G6iXFybGhQdsjDct   \n",
       "1  27syMcotb279YaP2u-44wNFcfPQZ9PJGKFA  27syMcotb279YaP2u  44wNFcfPQZ9PJGKFA   \n",
       "2  27syMcotb279YaP2u-A9peJrKgSA7qng696  27syMcotb279YaP2u  A9peJrKgSA7qng696   \n",
       "3  27syMcotb279YaP2u-GALL37sjanTe42yDq  27syMcotb279YaP2u  GALL37sjanTe42yDq   \n",
       "4  27syMcotb279YaP2u-KQeEk3nih5NnRFRvn  27syMcotb279YaP2u  KQeEk3nih5NnRFRvn   \n",
       "\n",
       "                timestamp  user_count user_parity odd_handling  \\\n",
       "0 2023-04-13 08:43:23.516           7         odd       remove   \n",
       "1 2023-05-02 01:52:25.623          10        even       remove   \n",
       "2 2023-04-24 03:47:02.227          10        even       remove   \n",
       "3 2023-04-13 08:42:46.621           7         odd       remove   \n",
       "4 2023-04-23 15:44:15.341           8        even       remove   \n",
       "\n",
       "                   final_matching  \\\n",
       "0          [2, 5, 0, -1, 6, 1, 4]   \n",
       "1  [3, 7, 6, 0, 5, 4, 2, 1, 9, 8]   \n",
       "2  [7, 9, 6, 5, 8, 3, 2, 0, 4, 1]   \n",
       "3          [5, -1, 6, 4, 3, 0, 2]   \n",
       "4        [6, 2, 1, 7, 5, 4, 0, 3]   \n",
       "\n",
       "                                    final_affinities  \\\n",
       "0  {'TFpfXZLxwfzEorfGD': 0, 'SKMaq7QzxYcNddSoT': ...   \n",
       "1  {'TFpfXZLxwfzEorfGD': 1, '66PYzPiXdpro84gaR': ...   \n",
       "2  {'TFpfXZLxwfzEorfGD': 1, '66PYzPiXdpro84gaR': ...   \n",
       "3  {'TFpfXZLxwfzEorfGD': 0, '7Bu7DRa9Js5B2SkP2': ...   \n",
       "4  {'TFpfXZLxwfzEorfGD': 0, 'SKMaq7QzxYcNddSoT': ...   \n",
       "\n",
       "                        sr_result  ...                              sr_debug  \\\n",
       "0          [2, 5, 0, -1, 6, 1, 4]  ...  Stable matching found after Phase 1.   \n",
       "1  [3, 7, 6, 0, 5, 4, 2, 1, 9, 8]  ...  Stable matching found after Phase 1.   \n",
       "2  [7, 9, 6, 5, 8, 3, 2, 0, 4, 1]  ...  Stable matching found after Phase 1.   \n",
       "3          [5, -1, 6, 4, 3, 0, 2]  ...  Stable matching found after Phase 1.   \n",
       "4        [6, 2, 1, 7, 5, 4, 0, 3]  ...  Stable matching found after Phase 2.   \n",
       "\n",
       "  sr_cardinality                      mwm_result  \\\n",
       "0              6          [6, 3, -1, 1, 5, 4, 0]   \n",
       "1             10  [4, 7, 6, 5, 0, 3, 2, 1, 9, 8]   \n",
       "2             10  [3, 9, 6, 0, 5, 4, 2, 8, 7, 1]   \n",
       "3              6          [5, 3, 6, 1, -1, 0, 2]   \n",
       "4              8        [6, 7, 3, 2, 5, 4, 0, 1]   \n",
       "\n",
       "                                      mwm_affinities mwm_stability  \\\n",
       "0  {'66PYzPiXdpro84gaR': 0, 'TFpfXZLxwfzEorfGD': ...      unstable   \n",
       "1  {'sanGBbAp7tXpTMfHN': 3, '7Bu7DRa9Js5B2SkP2': ...      unstable   \n",
       "2  {'MP8Rx75gtnRvDZgFk': 0, 'wkEeKMNEDceiNrmnZ': ...      unstable   \n",
       "3  {'sanGBbAp7tXpTMfHN': 5, 'SKMaq7QzxYcNddSoT': ...      unstable   \n",
       "4  {'2y7tESxwQFwro8Jca': 4, 'sanGBbAp7tXpTMfHN': ...      unstable   \n",
       "\n",
       "                                     affinity_matrix  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "1  [[0, -1.0, -1.0, -1.0, 0, 0.66, -1.0, -1.0, -1...   \n",
       "2  [[0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, ...   \n",
       "3  [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],...   \n",
       "4  [[0, 0, 0, -1.0, -1.0, 0, 0, -1.0], [0, 0, 0, ...   \n",
       "\n",
       "                                      directed_graph  \\\n",
       "0  [[0, 65, 33, 53, 85, 81, 82], [61, 0, 72, 75, ...   \n",
       "1  [[0, -96, -96, -84, 61, 108, -98, -97, -94, -8...   \n",
       "2  [[0, -87, -98, 62, -94, -86, -87, -84, -84, -9...   \n",
       "3  [[0, 42, 71, 62, 75, 83, 62], [45, 0, 65, 79, ...   \n",
       "4  [[0, 53, 53, -84, -88, 22, 51, -97], [75, 0, 8...   \n",
       "\n",
       "                                    undirected_graph  \\\n",
       "0  [[0, 1, 78], [0, 2, 48], [0, 3, 58], [0, 5, 12...   \n",
       "1  [[0, 4, 62], [0, 5, 71], [1, 2, 82], [1, 3, 93...   \n",
       "2  [[0, 3, 115], [1, 2, 82], [1, 3, 89], [1, 4, 7...   \n",
       "3  [[0, 1, 34], [0, 2, 78], [0, 3, 74], [0, 5, 13...   \n",
       "4  [[0, 1, 56], [0, 2, 119], [0, 5, 74], [0, 6, 8...   \n",
       "\n",
       "                                   preference_matrix  \\\n",
       "0  [[5, 7, 6, 2, 4, 3], [6, 4, 3, 5, 1, 7], [2, 6...   \n",
       "1  [[6, 5, 4, 10, 9, 2, 3, 8, 7], [8, 9, 3, 1, 5,...   \n",
       "2  [[4, 8, 9, 6, 2, 7, 10, 5, 3], [4, 10, 1, 7, 3...   \n",
       "3  [[6, 5, 3, 4, 7, 2], [4, 5, 7, 6, 3, 1], [2, 1...   \n",
       "4  [[2, 3, 7, 6, 4, 5, 8], [8, 6, 3, 4, 7, 1, 5],...   \n",
       "\n",
       "                                  index_user_mapping  \n",
       "0  {'0': 'TFpfXZLxwfzEorfGD', '1': 'SKMaq7QzxYcNd...  \n",
       "1  {'0': 'TFpfXZLxwfzEorfGD', '1': '66PYzPiXdpro8...  \n",
       "2  {'0': 'TFpfXZLxwfzEorfGD', '1': '66PYzPiXdpro8...  \n",
       "3  {'0': 'TFpfXZLxwfzEorfGD', '1': 'SKMaq7QzxYcNd...  \n",
       "4  {'0': 'TFpfXZLxwfzEorfGD', '1': 'SKMaq7QzxYcNd...  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all pairing instances\n",
    "group_pairing_ids = affinities_history.group_pairing_id.unique()\n",
    "\n",
    "# compute pairings and create DataFrame of results\n",
    "remove_all_pairings_df = execute_sr_matching(\n",
    "    group_pairing_ids, handle_odd_method=\"remove\", remove_all=True, parallel=False\n",
    ")\n",
    "\n",
    "# print stable matching results\n",
    "sr_stable_count = len(\n",
    "    remove_all_pairings_df[remove_all_pairings_df[\"sr_stability\"] == \"stable\"]\n",
    ")\n",
    "sr_unstable_count = len(\n",
    "    remove_all_pairings_df[remove_all_pairings_df[\"sr_stability\"] == \"unstable\"]\n",
    ")\n",
    "sr_total = sr_stable_count + sr_unstable_count\n",
    "\n",
    "output_string = \"Stable Roommates Matching Results\\nStable: {} ({:1.2f}%)\\nUnstable: {} ({:1.2f}%)\\nTotal: {} (100.00%)\\n\\n\"\n",
    "print(\n",
    "    output_string.format(\n",
    "        sr_stable_count,\n",
    "        100 * sr_stable_count / sr_total,\n",
    "        sr_unstable_count,\n",
    "        100 * sr_unstable_count / sr_total,\n",
    "        sr_total,\n",
    "    )\n",
    ")\n",
    "\n",
    "# print mwm results\n",
    "mwm_stable_count = len(\n",
    "    remove_all_pairings_df[remove_all_pairings_df[\"mwm_stability\"] == \"stable\"]\n",
    ")\n",
    "mwm_unstable_count = len(\n",
    "    remove_all_pairings_df[remove_all_pairings_df[\"mwm_stability\"] == \"unstable\"]\n",
    ")\n",
    "mwm_none_count = len(\n",
    "    remove_all_pairings_df[remove_all_pairings_df[\"mwm_stability\"] == \"NA\"]\n",
    ")\n",
    "mwm_total = mwm_stable_count + mwm_unstable_count + mwm_none_count\n",
    "\n",
    "output_string = \"Maximum Weighted Matching Results\\nStable: {} ({:1.2f}%)\\nUnstable: {} ({:1.2f}%)\\nNA (could not determine stability): {} ({:1.2f}%)\\nTotal: {} (100.00%)\"\n",
    "print(\n",
    "    output_string.format(\n",
    "        mwm_stable_count,\n",
    "        100 * mwm_stable_count / mwm_total,\n",
    "        mwm_unstable_count,\n",
    "        100 * mwm_unstable_count / mwm_total,\n",
    "        mwm_none_count,\n",
    "        100 * mwm_none_count / mwm_total,\n",
    "        mwm_total,\n",
    "    )\n",
    ")\n",
    "remove_all_pairings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Instability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "- why wasnt a person proposed to? --> see this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_all_pairings_df[[\"sr_stability\", \"sr_debug\", \"group_pair_id\"]].groupby(\n",
    "    [\"sr_stability\", \"sr_debug\"]\n",
    ").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_all_pairings_df[\n",
    "    [\"sr_stability\", \"sr_debug\", \"user_parity\", \"group_pair_id\"]\n",
    "].groupby([\"sr_stability\", \"sr_debug\", \"user_parity\"]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unstable Case 1--Failed at Phase 1: not everyone was proposed to.\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unstable_cases_1 = remove_all_pairings_df[\n",
    "    remove_all_pairings_df[\"sr_debug\"]\n",
    "    == \"Failed at Phase 1: not everyone was proposed to.\"\n",
    "]\n",
    "unstable_cases_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute proportion of return matching that was stable\n",
    "unstable_cases_1[\"partial_stability_proportion\"] = unstable_cases_1.apply(\n",
    "    lambda x: 100.0 * (x[\"sr_cardinality\"] / x[\"user_count\"]), axis=1\n",
    ")\n",
    "unstable_cases_1[\"partial_stability_proportion\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unstable Case 2--Failed at Phase 2: could not find an all-or-nothing cycle len > 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unstable_cases_2 = remove_all_pairings_df[\n",
    "    remove_all_pairings_df[\"sr_debug\"]\n",
    "    == \"Failed at Phase 2: could not find an all-or-nothing cycle len > 3.\"\n",
    "]\n",
    "unstable_cases_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute proportion of return matching that was stable\n",
    "unstable_cases_2[\"partial_stability_proportion\"] = unstable_cases_2.apply(\n",
    "    lambda x: 100.0 * (x[\"sr_cardinality\"] / x[\"user_count\"]), axis=1\n",
    ")\n",
    "unstable_cases_2[\"partial_stability_proportion\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unstable Case 3--Failed at Verification after Phase 2: matching computed, but not valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unstable_cases_3 = remove_all_pairings_df[\n",
    "    remove_all_pairings_df[\"sr_debug\"]\n",
    "    == \"Failed at Verification after Phase 2: matching computed, but not valid.\"\n",
    "]\n",
    "unstable_cases_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute proportion of return matching that was stable\n",
    "unstable_cases_3[\"partial_stability_proportion\"] = unstable_cases_3.apply(\n",
    "    lambda x: 100.0 * (x[\"sr_cardinality\"] / x[\"user_count\"]), axis=1\n",
    ")\n",
    "unstable_cases_3[\"partial_stability_proportion\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Matching Affinities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get affinities\n",
    "sr_affinties = [\n",
    "    inner\n",
    "    for outer in remove_one_pairings_df[\"sr_affinities\"].tolist()\n",
    "    for inner in outer.values()\n",
    "]\n",
    "sr_affinities_df = (\n",
    "    pd.DataFrame({\"affinities\": sr_affinties})\n",
    "    .groupby(\"affinities\")[\"affinities\"]\n",
    "    .count()\n",
    "    .reset_index(name=\"count\")\n",
    ")\n",
    "sr_affinities_df[\"proportion\"] = sr_affinities_df[\"count\"] / sum(\n",
    "    sr_affinities_df[\"count\"]\n",
    ")\n",
    "sr_affinities_df[\"percentage\"] = 100 * sr_affinities_df[\"proportion\"]\n",
    "sr_affinities_df[\"algorithm\"] = \"stable only\"\n",
    "\n",
    "mwm_affinities = [\n",
    "    inner\n",
    "    for outer in remove_one_pairings_df[\"mwm_affinities\"].tolist()\n",
    "    for inner in outer.values()\n",
    "]\n",
    "mwm_affinities_df = (\n",
    "    pd.DataFrame({\"affinities\": mwm_affinities})\n",
    "    .groupby(\"affinities\")[\"affinities\"]\n",
    "    .count()\n",
    "    .reset_index(name=\"count\")\n",
    ")\n",
    "mwm_affinities_df[\"proportion\"] = mwm_affinities_df[\"count\"] / sum(\n",
    "    mwm_affinities_df[\"count\"]\n",
    ")\n",
    "mwm_affinities_df[\"percentage\"] = 100 * mwm_affinities_df[\"proportion\"]\n",
    "mwm_affinities_df[\"algorithm\"] = \"mwm only\"\n",
    "\n",
    "sr_mwm_affinities = [\n",
    "    inner\n",
    "    for outer in remove_one_pairings_df[\"final_affinities\"].tolist()\n",
    "    for inner in outer.values()\n",
    "]\n",
    "sr_mwm_affinities_df = (\n",
    "    pd.DataFrame({\"affinities\": sr_mwm_affinities})\n",
    "    .groupby(\"affinities\")[\"affinities\"]\n",
    "    .count()\n",
    "    .reset_index(name=\"count\")\n",
    ")\n",
    "sr_mwm_affinities_df[\"proportion\"] = sr_mwm_affinities_df[\"count\"] / sum(\n",
    "    sr_mwm_affinities_df[\"count\"]\n",
    ")\n",
    "sr_mwm_affinities_df[\"percentage\"] = 100 * sr_mwm_affinities_df[\"proportion\"]\n",
    "sr_mwm_affinities_df[\"algorithm\"] = \"stable + mwm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize=(20, 8))\n",
    "ax = sns.barplot(\n",
    "    data=pd.concat([mwm_affinities_df, sr_affinities_df, sr_mwm_affinities_df]),\n",
    "    x=\"affinities\",\n",
    "    y=\"percentage\",\n",
    "    hue=\"algorithm\",\n",
    ")\n",
    "\n",
    "ax.set_title(\"Affinity Given to Matched Partner\")\n",
    "ax.set_xlabel(\"Affinity Value\")\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "ax.set_ylim(0, 41)\n",
    "ax.set_yticks(range(0, 41, 2))\n",
    "\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    if math.isnan(height):\n",
    "        height = 0\n",
    "        ax.text(p.get_x() + p.get_width() / 2, height + 0.5, \"\", ha=\"center\")\n",
    "    else:\n",
    "        ax.text(\n",
    "            p.get_x() + p.get_width() / 2,\n",
    "            height + 1,\n",
    "            \"{:1.2f}%\".format(height),\n",
    "            ha=\"center\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Specific Pairing Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefs = [\n",
    "    [11, 2, 7, 4, 10, 12, 9, 5, 8, 6, 3],\n",
    "    [4, 1, 7, 11, 9, 12, 5, 3, 6, 8, 10],\n",
    "    [8, 1, 7, 5, 9, 6, 4, 2, 12, 11, 10],\n",
    "    [7, 1, 2, 11, 6, 12, 8, 5, 10, 9, 3],\n",
    "    [1, 2, 9, 4, 7, 6, 11, 12, 3, 10, 8],\n",
    "    [12, 10, 4, 1, 2, 7, 9, 5, 11, 8, 3],\n",
    "    [4, 2, 5, 11, 12, 1, 8, 9, 3, 10, 6],\n",
    "    [3, 10, 12, 5, 4, 11, 6, 9, 1, 7, 2],\n",
    "    [11, 10, 5, 12, 1, 3, 4, 7, 6, 8, 2],\n",
    "    [2, 4, 6, 1, 9, 5, 12, 8, 3, 7, 11],\n",
    "    [9, 10, 1, 4, 3, 7, 2, 12, 6, 8, 5],\n",
    "    [11, 7, 10, 1, 6, 9, 8, 3, 2, 4, 5],\n",
    "]\n",
    "\n",
    "preferences_dict = {str(x + 1): [str(y) for y in prefs[x]] for x in range(len(prefs))}\n",
    "ranks = {\n",
    "    index: dict(zip(value, range(len(value))))\n",
    "    for (index, value) in preferences_dict.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester_group_pair_id = \"2rFoGTfRa9LFdpQNA-2EPbA6HkydPTdxCWD\"\n",
    "temp_affinities = affinities_history[\n",
    "    affinities_history[\"group_pairing_id\"] == tester_group_pair_id\n",
    "]\n",
    "temp_affinities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_prev_matching = get_previous_matching(tester_group_pair_id)\n",
    "temp_prev_matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = {}\n",
    "for helper, match in temp_prev_matching.items():\n",
    "    curr_affinity = temp_affinities[\n",
    "        (temp_affinities[\"helperId\"] == helper) & (temp_affinities[\"helpeeId\"] == match)\n",
    "    ][\"value\"].tolist()\n",
    "\n",
    "    if len(curr_affinity) > 0:\n",
    "        output_dict[helper] = curr_affinity[0]\n",
    "    else:\n",
    "        print(\"no affinity\")\n",
    "        output_dict[helper] = 0\n",
    "\n",
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create affinity matrix and index-user dict\n",
    "curr_affinities = deepcopy(\n",
    "    affinities_history[affinities_history[\"group_pairing_id\"] == tester_group_pair_id]\n",
    ")\n",
    "curr_tasks = deepcopy(\n",
    "    tasks_history[tasks_history[\"group_pairing_id\"] == tester_group_pair_id]\n",
    ")\n",
    "curr_affinity_matrix, curr_index_user_mapping = create_affinity_matrix(\n",
    "    curr_affinities[[\"helperId\", \"helpeeId\", \"value\"]], curr_tasks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = sr_matching_pair_research(\"2rFoGTfRa9LFdpQNA-2EPbA6HkydPTdxCWD\")\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[\"final_matching\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naming_dict = {\n",
    "    k: users[users._id == v][\"profile\"].tolist()[0][\"fullName\"]\n",
    "    for k, v in temp[\"index_user_mapping\"].items()\n",
    "}\n",
    "naming_dict[\"-1\"] = \"\"\n",
    "naming_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    naming_dict[str(index)]: naming_dict[str(value)]\n",
    "    for index, value in enumerate(temp[\"final_matching\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    (pairing[\"firstUserName\"], pairing[\"secondUserName\"])\n",
    "    for pairing in pairings[\n",
    "        pairings[\"group_pairing_id\"] == \"9mdkMmj4pY8Q2TwqF-KPcJQn2ximvZmjEhf\"\n",
    "    ][\"pairings\"].tolist()[0]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    (pairing[\"firstUserName\"], pairing[\"secondUserName\"])\n",
    "    for pairing in pairings[\n",
    "        pairings[\"group_pairing_id\"] == \"9mdkMmj4pY8Q2TwqF-7DyTNMHyXyHsSPTBY\"\n",
    "    ][\"pairings\"].tolist()[0]\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
